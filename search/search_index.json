{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#sptnano","title":"SPTnano","text":"<p>Pipeline for easy single particle detection, linking/tracking, and analysis</p> <p>This project is developed in collaboration with the Centre for Advanced Research Computing, University College London.</p>"},{"location":"#about","title":"About","text":""},{"location":"#project-team","title":"Project Team","text":"<p>Michael Shannon (m.j.shannon@pm.me)</p>"},{"location":"#research-software-engineering-contact","title":"Research Software Engineering Contact","text":"<p>Centre for Advanced Research Computing, University College London (arc.collaborations@ucl.ac.uk)</p>"},{"location":"#built-with","title":"Built With","text":"<ul> <li>Framework 1</li> <li>Framework 2</li> <li>Framework 3</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<p><code>SPTnano</code> requires Python 3.10\u20133.12.</p>"},{"location":"#installation","title":"Installation","text":"<p>We recommend installing in a project specific virtual environment created using a environment management tool such as Conda. To install the latest development version of <code>SPTnano</code> using <code>pip</code> in the currently active environment run</p> <pre><code>pip install git+https://github.com/Michael-shannon/SPTnano.git\n</code></pre> <p>Alternatively create a local clone of the repository with</p> <pre><code>git clone https://github.com/Michael-shannon/SPTnano.git\n</code></pre> <p>and then install in editable mode by running</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"#running-locally","title":"Running Locally","text":"<p>How to run the application on your local system.</p>"},{"location":"#running-tests","title":"Running Tests","text":"<p>Tests can be run across all compatible Python versions in isolated environments using <code>tox</code> by running</p> <pre><code>tox\n</code></pre> <p>To run tests manually in a Python environment with <code>pytest</code> installed run</p> <pre><code>pytest tests\n</code></pre> <p>again from the root of the repository.</p>"},{"location":"#building-documentation","title":"Building Documentation","text":"<p>The MkDocs HTML documentation can be built locally by running</p> <pre><code>tox -e docs\n</code></pre> <p>from the root of the repository. The built documentation will be written to <code>site</code>.</p> <p>Alternatively to build and preview the documentation locally, in a Python environment with the optional <code>docs</code> dependencies installed, run</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li> Initial Research</li> <li> Minimum viable product &lt;-- You are Here</li> <li> Alpha Release</li> <li> Feature-Complete Release</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This work was funded by Cure Huntingtons Disease Initiative (CHDI) and The Rockefeller University.</p>"},{"location":"LICENSE/","title":"License","text":""},{"location":"LICENSE/#mit-license","title":"MIT License","text":"<p>Copyright (c) 2024 Michael Shannon</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"api/","title":"API reference","text":"<p>SPTnano package.</p>"},{"location":"api/#SPTnano.add_microns_and_secs","title":"<code>add_microns_and_secs(df, pixelsize_microns, time_between_frames)</code>","text":"<p>Adds columns to the DataFrame with positions in microns and time in seconds</p> Source code in <code>src/SPTnano/helper_scripts.py</code> <pre><code>def add_microns_and_secs(df, pixelsize_microns, time_between_frames):\n    '''Adds columns to the DataFrame with positions in microns and time in seconds'''\n    #space transformations\n    df['x_um'] = df['x'] * pixelsize_microns\n    df['y_um'] = df['y'] * pixelsize_microns\n\n    df['frame_zeroed'] = df.groupby('particle')['frame'].transform(lambda x: x - x.iloc[0])\n    df['time_s'] = df['frame'] * time_between_frames\n    df['time_s_zeroed'] = df.groupby('particle')['time_s'].transform(lambda x: x - x.iloc[0])\n    return df\n</code></pre>"},{"location":"api/#SPTnano.batch_plot_trajectories","title":"<code>batch_plot_trajectories(master_folder, traj_df, batch=True, filename=None, colorby='particle', mpp=None, label=False, cmap=None)</code>","text":"<p>Batch plot trajectories for all replicates across several conditions.</p>"},{"location":"api/#SPTnano.batch_plot_trajectories--parameters","title":"Parameters","text":"<p>master_folder : str     Path to the master folder containing 'data' and 'saved_data' folders. traj_df : DataFrame     The DataFrame containing trajectory data. batch : bool, optional     If True, plots trajectories for all replicates in batch mode.     If False, plots trajectory for the specified filename. filename : str, optional     Filename of interest when batch is False. colorby : str, optional     Color by 'particle' or 'frame'. mpp : float, optional     Microns per pixel. label : bool, optional     Set to True to write particle ID numbers next to trajectories. cmap : colormap, optional     Colormap to use for coloring tracks.</p> Source code in <code>src/SPTnano/visualization.py</code> <pre><code>def batch_plot_trajectories(master_folder, traj_df, batch=True, filename=None, colorby='particle', mpp=None, label=False, cmap=None):\n    \"\"\"\n    Batch plot trajectories for all replicates across several conditions.\n\n    Parameters\n    ----------\n    master_folder : str\n        Path to the master folder containing 'data' and 'saved_data' folders.\n    traj_df : DataFrame\n        The DataFrame containing trajectory data.\n    batch : bool, optional\n        If True, plots trajectories for all replicates in batch mode.\n        If False, plots trajectory for the specified filename.\n    filename : str, optional\n        Filename of interest when batch is False.\n    colorby : str, optional\n        Color by 'particle' or 'frame'.\n    mpp : float, optional\n        Microns per pixel.\n    label : bool, optional\n        Set to True to write particle ID numbers next to trajectories.\n    cmap : colormap, optional\n        Colormap to use for coloring tracks.\n    \"\"\"\n    data_folder = os.path.join(master_folder, 'data')\n    vis_folder = os.path.join(master_folder, 'visualization')\n    os.makedirs(vis_folder, exist_ok=True)\n\n    if batch:\n        for condition in os.listdir(data_folder):\n            condition_folder = os.path.join(data_folder, condition)\n            if os.path.isdir(condition_folder):\n                for file in os.listdir(condition_folder):\n                    if file.endswith('.tif'):\n                        filepath = os.path.join(condition_folder, file)\n                        subset_traj_df = traj_df[traj_df['filename'] == file]\n                        if not subset_traj_df.empty:\n                            frames = pims.open(filepath)\n                            frame = frames[0]\n                            fig, ax = plt.subplots()\n                            plot_trajectory(subset_traj_df, colorby=colorby, mpp=mpp, label=label, superimpose=frame, cmap=cmap, ax=ax)\n                            plt.savefig(os.path.join(vis_folder, f'{condition}_{file}.png'))\n                            plt.close(fig)\n    else:\n        if filename is not None:\n            filepath = os.path.join(data_folder, filename)\n            subset_traj_df = traj_df[traj_df['filename'] == filename]\n            if not subset_traj_df.empty:\n                frames = pims.open(filepath)\n                frame = frames[0]\n                fig, ax = plt.subplots()\n                plot_trajectory(subset_traj_df, colorby=colorby, mpp=mpp, label=label, superimpose=frame, cmap=cmap, ax=ax)\n                plt.show()\n        else:\n            print(\"Please provide a filename when batch is set to False.\")\n</code></pre>"},{"location":"api/#SPTnano.example_function","title":"<code>example_function(argument, keyword_argument='default')</code>","text":"<p>Concatenate string arguments - an example function docstring.</p> <p>Parameters:</p> Name Type Description Default <code>argument</code> <code>str</code> <p>An argument.</p> required <code>keyword_argument</code> <code>str</code> <p>A keyword argument with a default value.</p> <code>'default'</code> <p>Returns:</p> Type Description <code>str</code> <p>The concatenation of <code>argument</code> and <code>keyword_argument</code>.</p> Source code in <code>src/SPTnano/__init__.py</code> <pre><code>def example_function(argument: str, keyword_argument: str = \"default\") -&gt; str:\n    \"\"\"\n    Concatenate string arguments - an example function docstring.\n\n    Args:\n        argument: An argument.\n        keyword_argument: A keyword argument with a default value.\n\n    Returns:\n        The concatenation of `argument` and `keyword_argument`.\n\n    \"\"\"\n    return argument + keyword_argument\n</code></pre>"},{"location":"api/#SPTnano.filter_high_speeds","title":"<code>filter_high_speeds(metrics_df, speed_threshold)</code>","text":"<p>Filter based on speed instead - can be relevant if you have different exposure times and different times between frames</p> Source code in <code>src/SPTnano/helper_scripts.py</code> <pre><code>def filter_high_speeds(metrics_df, speed_threshold):\n    '''\n    Filter based on speed instead - can be relevant if you have different exposure times and different times between frames\n    '''\n\n    # Identify unique_ids with any high speeds\n    high_speed_particles = metrics_df[metrics_df['speed_um_s'] &gt; speed_threshold]['unique_id'].unique()\n\n    # Filter out particles with high speeds\n    metrics_df_filtered = metrics_df[~metrics_df['unique_id'].isin(high_speed_particles)].copy()\n    return metrics_df_filtered\n</code></pre>"},{"location":"api/#SPTnano.filter_large_jumps","title":"<code>filter_large_jumps(df, threshold)</code>","text":"<p>Filter out entire particles with any frames showing large jumps in micrometers.</p>"},{"location":"api/#SPTnano.filter_large_jumps--parameters","title":"Parameters","text":"<p>df : DataFrame     DataFrame containing tracking data with a 'segment_len_um' column. threshold : float     Threshold for what constitutes a large jump in micrometers.</p>"},{"location":"api/#SPTnano.filter_large_jumps--returns","title":"Returns","text":"<p>DataFrame     DataFrame with particles having large jumps filtered out.</p> Source code in <code>src/SPTnano/helper_scripts.py</code> <pre><code>def filter_large_jumps(df, threshold):\n    \"\"\"\n    Filter out entire particles with any frames showing large jumps in micrometers.\n\n    Parameters\n    ----------\n    df : DataFrame\n        DataFrame containing tracking data with a 'segment_len_um' column.\n    threshold : float\n        Threshold for what constitutes a large jump in micrometers.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame with particles having large jumps filtered out.\n    \"\"\"\n    # Identify unique_ids with any large jumps\n    large_jump_particles = df[df['segment_len_um'] &gt; threshold]['unique_id'].unique()\n\n    # Filter out particles with large jumps\n    df_filtered = df[~df['unique_id'].isin(large_jump_particles)].copy()\n    # df_filtered.drop(columns=['x_um_prev', 'y_um_prev', 'segment_len_um'], inplace=True)\n    return df_filtered\n</code></pre>"},{"location":"api/#SPTnano.filter_stubs","title":"<code>filter_stubs(df, min_time)</code>","text":"<p>Removes tracks that are shorter than 'min_time' by finding the max duration of each time_s_zeroed column and filtering on that Works across exposure times, because it works on converted seconds, not frames</p> Source code in <code>src/SPTnano/helper_scripts.py</code> <pre><code>def filter_stubs(df, min_time):\n\n    '''\n    Removes tracks that are shorter than 'min_time' by finding the max duration of each time_s_zeroed column and filtering on that\n    Works across exposure times, because it works on converted seconds, not frames\n\n    '''\n    # Calculate the duration of each track by grouping by 'particle' and using the 'time_s' column\n    track_durations = df.groupby('unique_id')['time_s_zeroed'].max() \n    # Identify particles with tracks longer than 0.2 seconds\n    valid_particles = track_durations[track_durations &gt;= min_time].index\n    # Filter the dataframe to include only valid particles\n    filtered_df = df[df['unique_id'].isin(valid_particles)]\n\n    return filtered_df\n</code></pre>"},{"location":"api/#SPTnano.plot_histograms","title":"<code>plot_histograms(data_df, feature, bins=100, separate=None, xlimit=None, small_multiples=False, palette='colorblind')</code>","text":"<p>Plot histograms of a specified feature for each category in coltoseparate, with consistent binning.</p>"},{"location":"api/#SPTnano.plot_histograms--parameters","title":"Parameters","text":"<p>data_df : DataFrame     DataFrame containing track data with the specified feature and optionally a separating column. feature : str     The feature to plot histograms for. bins : int, optional     Number of bins for the histogram. Default is 100. coltoseparate : str, optional     Column to separate the data by. If None, all data will be plotted together. Default is None. xlimit : float, optional     Upper limit for the x-axis. Default is None. small_multiples : bool, optional     Whether to plot each category separately as small multiples. Default is False.</p> Source code in <code>src/SPTnano/visualization.py</code> <pre><code>def plot_histograms(data_df, feature, bins=100, separate=None, xlimit=None, small_multiples=False, palette='colorblind'):\n    \"\"\"\n    Plot histograms of a specified feature for each category in coltoseparate, with consistent binning.\n\n    Parameters\n    ----------\n    data_df : DataFrame\n        DataFrame containing track data with the specified feature and optionally a separating column.\n    feature : str\n        The feature to plot histograms for.\n    bins : int, optional\n        Number of bins for the histogram. Default is 100.\n    coltoseparate : str, optional\n        Column to separate the data by. If None, all data will be plotted together. Default is None.\n    xlimit : float, optional\n        Upper limit for the x-axis. Default is None.\n    small_multiples : bool, optional\n        Whether to plot each category separately as small multiples. Default is False.\n    \"\"\"\n    unique_categories = data_df[separate].unique() if separate else [None]\n    color_palette = sns.color_palette(palette, len(unique_categories))\n\n    if small_multiples and separate is not None:\n        num_categories = len(unique_categories)\n        fig, axes = plt.subplots(num_categories, 1, figsize=(20, 6 * num_categories), sharex=True)\n\n        if num_categories == 1:\n            axes = [axes]  # To handle the case with only one subplot\n\n        for i, category in enumerate(unique_categories):\n            subset = data_df[data_df[separate] == category]\n            subsetvalues = subset[feature]\n\n            max_value = subsetvalues.max()\n            bin_edges = np.linspace(0, max_value, bins + 1)\n\n            # Plot histogram\n            sns.histplot(subsetvalues, bins=bin_edges, kde=True, ax=axes[i], stat=\"percent\", color=color_palette[i])\n            axes[i].set_title(f'{category}', fontsize=14)\n\n            mean_value = subsetvalues.mean()\n            median_value = subsetvalues.median()\n            number_of_tracks = len(subset['unique_id'].unique())\n            axes[i].text(0.4, 0.6, f\"Mean: {mean_value:.2f}, Median: {median_value:.2f}, Tracks: {number_of_tracks}\", transform=axes[i].transAxes, fontsize=10)\n\n            if xlimit is not None:\n                axes[i].set_xlim(0, xlimit)\n            else:\n                axes[i].set_xlim(0, max_value)\n\n        plt.xlabel(f'{feature}', fontsize=12)\n        plt.tight_layout()\n        plt.show()\n\n    else:\n        plt.figure(figsize=(20, 12))\n        size = 10\n        multiplier = 2\n        sns.set_context(\"notebook\", rc={\"xtick.labelsize\": size * multiplier, \"ytick.labelsize\": size * multiplier})\n\n        max_value = data_df[feature].max()\n        bin_edges = np.linspace(0, max_value, bins + 1)\n\n        if separate is None:\n            subsetvalues = data_df[feature]\n\n            # Calculate percentage counts\n            counts, _ = np.histogram(subsetvalues, bins=bin_edges)\n            percentage_counts = (counts / counts.sum()) * 100\n\n            # Plot histogram\n            sns.histplot(subsetvalues, bins=bin_edges, kde=True, alpha=0.5, stat=\"percent\", color=color_palette[0])\n\n            mean_value = subsetvalues.mean()\n            median_value = subsetvalues.median()\n            plt.text(0.4, 0.6, f\"Overall: mean: {mean_value:.2f}, median: {median_value:.2f}\", transform=plt.gca().transAxes, fontsize=10 * multiplier)\n\n        else:\n            for i, category in enumerate(unique_categories):\n                subset = data_df[data_df[separate] == category]\n                subsetvalues = subset[feature]\n\n                # Calculate percentage counts\n                counts, _ = np.histogram(subsetvalues, bins=bin_edges)\n                percentage_counts = (counts / counts.sum()) * 100\n\n                # Plot histogram\n                sns.histplot(subsetvalues, bins=bin_edges, kde=True, label=category, alpha=0.5, stat=\"percent\", color=color_palette[i])\n\n                mean_value = subsetvalues.mean()\n                median_value = subsetvalues.median()\n                number_of_tracks = len(subset['unique_id'].unique())\n                shift = i * 0.05\n                plt.text(0.4, 0.6 - shift, f\"{category}: mean: {mean_value:.2f} from {number_of_tracks} tracks\", transform=plt.gca().transAxes, fontsize=10 * multiplier)\n\n        plt.xlabel(f'{feature}', fontsize=size * multiplier)\n        plt.ylabel('Percentage', fontsize=size * multiplier)\n        plt.legend(title='', fontsize=size * multiplier)\n        ax = plt.gca()\n        if xlimit is not None:\n            ax.set_xlim(0, xlimit)\n        else:\n            ax.set_xlim(0, max_value)\n        plt.show()\n</code></pre>"},{"location":"api/#SPTnano.plot_histograms_seconds","title":"<code>plot_histograms_seconds(traj_df, bins=100, coltoseparate='tracker', xlimit=None)</code>","text":"<p>Plot histograms of track lengths in seconds for each tracker, with consistent binning.</p>"},{"location":"api/#SPTnano.plot_histograms_seconds--parameters","title":"Parameters","text":"<p>traj_df : DataFrame     DataFrame containing track data with columns 'tracker', 'unique_id', 'time_s_zeroed', and 'filename'. bins : int, optional     Number of bins for the histogram. Default is 100. coltoseparate : str, optional     Column to separate the data by. Default is 'tracker'. xlimit : float, optional     Upper limit for the x-axis. Default is None.</p> Source code in <code>src/SPTnano/visualization.py</code> <pre><code>def plot_histograms_seconds(traj_df, bins=100, coltoseparate='tracker', xlimit=None):\n    \"\"\"\n    Plot histograms of track lengths in seconds for each tracker, with consistent binning.\n\n    Parameters\n    ----------\n    traj_df : DataFrame\n        DataFrame containing track data with columns 'tracker', 'unique_id', 'time_s_zeroed', and 'filename'.\n    bins : int, optional\n        Number of bins for the histogram. Default is 100.\n    coltoseparate : str, optional\n        Column to separate the data by. Default is 'tracker'.\n    xlimit : float, optional\n        Upper limit for the x-axis. Default is None.\n    \"\"\"\n    plt.figure(figsize=(20, 12))\n    size = 10\n    multiplier = 2\n    sns.set_context(\"notebook\", rc={\"xtick.labelsize\": size*multiplier, \"ytick.labelsize\": size*multiplier})\n\n    max_track_length = traj_df.groupby('unique_id')['time_s_zeroed'].max().max()\n    bin_edges = np.linspace(0, max_track_length, bins + 1)\n\n    for i, tracker in enumerate(traj_df[coltoseparate].unique()):\n        subset = traj_df[traj_df[coltoseparate] == tracker]\n        subsetvalues = subset.groupby('unique_id')['time_s_zeroed'].max()\n\n        # Calculate percentage counts\n        counts, _ = np.histogram(subsetvalues, bins=bin_edges)\n        percentage_counts = (counts / counts.sum()) * 100\n\n        # Plot histogram\n        sns.histplot(subsetvalues, bins=bin_edges, kde=True, label=tracker, alpha=0.5, stat=\"percent\")\n\n        subset_mean = subsetvalues.mean()\n        subset_median = subsetvalues.median()\n        subset_number_of_tracks = len(subset['unique_id'].unique())\n        shift = i * 0.05\n        plt.text(0.4, 0.6 - shift, f\"{tracker}: mean: {subset_mean:.2f} seconds from {subset_number_of_tracks} tracks\", transform=plt.gca().transAxes, fontsize=10 * multiplier)\n\n    plt.xlabel('Track length (seconds)', fontsize=size * multiplier)\n    plt.ylabel('Percentage', fontsize=size * multiplier)\n    plt.legend(title='', fontsize=size * multiplier)\n    ax = plt.gca()\n    if xlimit is not None:\n        ax.set_xlim(0, xlimit)\n    else:\n        ax.set_xlim(0, max_track_length)\n    plt.show()\n</code></pre>"},{"location":"api/#SPTnano.plot_trajectory","title":"<code>plot_trajectory(traj, colorby='particle', mpp=None, label=False, superimpose=None, cmap=None, ax=None, t_column=None, pos_columns=None, plot_style={}, **kwargs)</code>","text":"<p>Plot traces of trajectories for each particle. Optionally superimpose it on a frame from the video.</p>"},{"location":"api/#SPTnano.plot_trajectory--parameters","title":"Parameters","text":"<p>traj : DataFrame     The DataFrame should include time and spatial coordinate columns. colorby : {'particle', 'frame'}, optional mpp : float, optional     Microns per pixel. If omitted, the labels will have units of pixels. label : boolean, optional     Set to True to write particle ID numbers next to trajectories. superimpose : ndarray, optional     Background image, default None cmap : colormap, optional     This is only used in colorby='frame' mode. Default = mpl.cm.winter ax : matplotlib axes object, optional     Defaults to current axes t_column : string, optional     DataFrame column name for time coordinate. Default is 'frame'. pos_columns : list of strings, optional     Dataframe column names for spatial coordinates. Default is ['x', 'y']. plot_style : dictionary     Keyword arguments passed through to the <code>Axes.plot(...)</code> command</p>"},{"location":"api/#SPTnano.plot_trajectory--returns","title":"Returns","text":"<p>Axes object</p> Source code in <code>src/SPTnano/visualization.py</code> <pre><code>def plot_trajectory(traj, colorby='particle', mpp=None, label=False,\n                    superimpose=None, cmap=None, ax=None, t_column=None,\n                    pos_columns=None, plot_style={}, **kwargs):\n    \"\"\"\n    Plot traces of trajectories for each particle.\n    Optionally superimpose it on a frame from the video.\n\n    Parameters\n    ----------\n    traj : DataFrame\n        The DataFrame should include time and spatial coordinate columns.\n    colorby : {'particle', 'frame'}, optional\n    mpp : float, optional\n        Microns per pixel. If omitted, the labels will have units of pixels.\n    label : boolean, optional\n        Set to True to write particle ID numbers next to trajectories.\n    superimpose : ndarray, optional\n        Background image, default None\n    cmap : colormap, optional\n        This is only used in colorby='frame' mode. Default = mpl.cm.winter\n    ax : matplotlib axes object, optional\n        Defaults to current axes\n    t_column : string, optional\n        DataFrame column name for time coordinate. Default is 'frame'.\n    pos_columns : list of strings, optional\n        Dataframe column names for spatial coordinates. Default is ['x', 'y'].\n    plot_style : dictionary\n        Keyword arguments passed through to the `Axes.plot(...)` command\n\n    Returns\n    -------\n    Axes object\n    \"\"\"\n    if cmap is None:\n        cmap = plt.cm.winter\n    if t_column is None:\n        t_column = 'frame'\n    if pos_columns is None:\n        pos_columns = ['x', 'y']\n    if len(traj) == 0:\n        raise ValueError(\"DataFrame of trajectories is empty.\")\n\n    _plot_style = dict(linewidth=1)\n    _plot_style.update(**plot_style)\n\n    if ax is None:\n        ax = plt.gca()\n\n    # Axes labels\n    if mpp is None:\n        ax.set_xlabel(f'{pos_columns[0]} [px]')\n        ax.set_ylabel(f'{pos_columns[1]} [px]')\n        mpp = 1.  # for computations of image extent below\n    else:\n        ax.set_xlabel(f'{pos_columns[0]} [\u03bcm]')\n        ax.set_ylabel(f'{pos_columns[1]} [\u03bcm]')\n\n    # Background image\n    if superimpose is not None:\n        ax.imshow(superimpose, cmap=plt.cm.gray,\n                  origin='lower', interpolation='nearest',\n                  vmin=kwargs.get('vmin'), vmax=kwargs.get('vmax'))\n        ax.set_xlim(-0.5 * mpp, (superimpose.shape[1] - 0.5) * mpp)\n        ax.set_ylim(-0.5 * mpp, (superimpose.shape[0] - 0.5) * mpp)\n\n    # Trajectories\n    if colorby == 'particle':\n        # Unstack particles into columns.\n        unstacked = traj.set_index(['particle', t_column])[pos_columns].unstack()\n        for i, trajectory in unstacked.iterrows():\n            ax.plot(mpp * trajectory[pos_columns[0]], mpp * trajectory[pos_columns[1]], **_plot_style)\n    elif colorby == 'frame':\n        # Read http://www.scipy.org/Cookbook/Matplotlib/MulticoloredLine\n        x = traj.set_index([t_column, 'particle'])[pos_columns[0]].unstack()\n        y = traj.set_index([t_column, 'particle'])[pos_columns[1]].unstack()\n        color_numbers = traj[t_column].values / float(traj[t_column].max())\n        for particle in x:\n            points = np.array([x[particle].values, y[particle].values]).T.reshape(-1, 1, 2)\n            segments = np.concatenate([points[:-1], points[1:]], axis=1)\n            lc = LineCollection(segments, cmap=cmap)\n            lc.set_array(color_numbers)\n            ax.add_collection(lc)\n            ax.set_xlim(x.apply(np.min).min(), x.apply(np.max).max())\n            ax.set_ylim(y.apply(np.min).min(), y.apply(np.max).max())\n\n    if label:\n        unstacked = traj.set_index([t_column, 'particle'])[pos_columns].unstack()\n        first_frame = int(traj[t_column].min())\n        coords = unstacked.fillna(method='backfill').stack().loc[first_frame]\n        for particle_id, coord in coords.iterrows():\n            ax.text(*coord.tolist(), s=\"%d\" % particle_id,\n                    horizontalalignment='center',\n                    verticalalignment='center')\n\n    ax.invert_yaxis()\n    return ax\n</code></pre>"},{"location":"api/#SPTnano.features","title":"<code>features</code>","text":""},{"location":"api/#SPTnano.features.ParticleMetrics","title":"<code>ParticleMetrics</code>","text":"Source code in <code>src/SPTnano/features.py</code> <pre><code>class ParticleMetrics:\n    def __init__(self, df):\n        self.df = df\n        self.metrics_df = self.df.copy()\n\n    def calculate_distances(self):\n        \"\"\"\n        Calculate the distances between consecutive frames for each particle in micrometers.\n        \"\"\"\n        self.metrics_df = self.metrics_df.sort_values(by=['unique_id', 'frame'])\n        self.metrics_df[['x_um_prev', 'y_um_prev']] = self.metrics_df.groupby('unique_id')[['x_um', 'y_um']].shift(1)\n        self.metrics_df['segment_len_um'] = np.sqrt(\n            (self.metrics_df['x_um'] - self.metrics_df['x_um_prev'])**2 + \n            (self.metrics_df['y_um'] - self.metrics_df['y_um_prev'])**2\n        )\n        # Fill NaN values with 0\n        self.metrics_df['segment_len_um'] = self.metrics_df['segment_len_um'].fillna(0)\n        return self.metrics_df\n\n    def calculate_speeds(self):\n        \"\"\"\n        Calculate the speed between consecutive frames for each particle in micrometers per second.\n        \"\"\"\n        self.metrics_df[['time_s_prev']] = self.metrics_df.groupby('unique_id')[['time_s']].shift(1)\n        self.metrics_df['delta_time_s'] = self.metrics_df['time_s'] - self.metrics_df['time_s_prev']\n        self.metrics_df['speed_um_s'] = self.metrics_df['segment_len_um'] / self.metrics_df['delta_time_s']\n        # Fill NaN and infinite values with 0\n        self.metrics_df['speed_um_s'] = self.metrics_df['speed_um_s'].replace([np.inf, -np.inf], np.nan).fillna(0)\n        return self.metrics_df\n\n    def calculate_all_features(self):\n        \"\"\"\n        Calculate all features for the particle tracking data.\n        This method will call all individual feature calculation methods.\n        \"\"\"\n        # Calculate distances between consecutive frames\n        self.calculate_distances()\n\n        # Calculate speeds between consecutive frames\n        self.calculate_speeds()\n\n        # Placeholder for additional feature calculations\n        # self.calculate_feature_X()\n        # self.calculate_feature_Y()\n\n        # Cleanup step to remove temporary columns\n        self.cleanup()\n\n        return self.metrics_df\n\n    def cleanup(self):\n        \"\"\"\n        Cleanup the dataframe by dropping unnecessary columns after all features are calculated.\n        \"\"\"\n        self.metrics_df.drop(columns=['x_um_prev', 'y_um_prev', 'time_s_prev', 'delta_time_s'], inplace=True)\n\n    def get_metrics_df(self):\n        \"\"\"\n        Return the dataframe with calculated metrics.\n        \"\"\"\n        return self.metrics_df\n</code></pre>"},{"location":"api/#SPTnano.features.ParticleMetrics.calculate_all_features","title":"<code>calculate_all_features()</code>","text":"<p>Calculate all features for the particle tracking data. This method will call all individual feature calculation methods.</p> Source code in <code>src/SPTnano/features.py</code> <pre><code>def calculate_all_features(self):\n    \"\"\"\n    Calculate all features for the particle tracking data.\n    This method will call all individual feature calculation methods.\n    \"\"\"\n    # Calculate distances between consecutive frames\n    self.calculate_distances()\n\n    # Calculate speeds between consecutive frames\n    self.calculate_speeds()\n\n    # Placeholder for additional feature calculations\n    # self.calculate_feature_X()\n    # self.calculate_feature_Y()\n\n    # Cleanup step to remove temporary columns\n    self.cleanup()\n\n    return self.metrics_df\n</code></pre>"},{"location":"api/#SPTnano.features.ParticleMetrics.calculate_distances","title":"<code>calculate_distances()</code>","text":"<p>Calculate the distances between consecutive frames for each particle in micrometers.</p> Source code in <code>src/SPTnano/features.py</code> <pre><code>def calculate_distances(self):\n    \"\"\"\n    Calculate the distances between consecutive frames for each particle in micrometers.\n    \"\"\"\n    self.metrics_df = self.metrics_df.sort_values(by=['unique_id', 'frame'])\n    self.metrics_df[['x_um_prev', 'y_um_prev']] = self.metrics_df.groupby('unique_id')[['x_um', 'y_um']].shift(1)\n    self.metrics_df['segment_len_um'] = np.sqrt(\n        (self.metrics_df['x_um'] - self.metrics_df['x_um_prev'])**2 + \n        (self.metrics_df['y_um'] - self.metrics_df['y_um_prev'])**2\n    )\n    # Fill NaN values with 0\n    self.metrics_df['segment_len_um'] = self.metrics_df['segment_len_um'].fillna(0)\n    return self.metrics_df\n</code></pre>"},{"location":"api/#SPTnano.features.ParticleMetrics.calculate_speeds","title":"<code>calculate_speeds()</code>","text":"<p>Calculate the speed between consecutive frames for each particle in micrometers per second.</p> Source code in <code>src/SPTnano/features.py</code> <pre><code>def calculate_speeds(self):\n    \"\"\"\n    Calculate the speed between consecutive frames for each particle in micrometers per second.\n    \"\"\"\n    self.metrics_df[['time_s_prev']] = self.metrics_df.groupby('unique_id')[['time_s']].shift(1)\n    self.metrics_df['delta_time_s'] = self.metrics_df['time_s'] - self.metrics_df['time_s_prev']\n    self.metrics_df['speed_um_s'] = self.metrics_df['segment_len_um'] / self.metrics_df['delta_time_s']\n    # Fill NaN and infinite values with 0\n    self.metrics_df['speed_um_s'] = self.metrics_df['speed_um_s'].replace([np.inf, -np.inf], np.nan).fillna(0)\n    return self.metrics_df\n</code></pre>"},{"location":"api/#SPTnano.features.ParticleMetrics.cleanup","title":"<code>cleanup()</code>","text":"<p>Cleanup the dataframe by dropping unnecessary columns after all features are calculated.</p> Source code in <code>src/SPTnano/features.py</code> <pre><code>def cleanup(self):\n    \"\"\"\n    Cleanup the dataframe by dropping unnecessary columns after all features are calculated.\n    \"\"\"\n    self.metrics_df.drop(columns=['x_um_prev', 'y_um_prev', 'time_s_prev', 'delta_time_s'], inplace=True)\n</code></pre>"},{"location":"api/#SPTnano.features.ParticleMetrics.get_metrics_df","title":"<code>get_metrics_df()</code>","text":"<p>Return the dataframe with calculated metrics.</p> Source code in <code>src/SPTnano/features.py</code> <pre><code>def get_metrics_df(self):\n    \"\"\"\n    Return the dataframe with calculated metrics.\n    \"\"\"\n    return self.metrics_df\n</code></pre>"},{"location":"api/#SPTnano.helper_scripts","title":"<code>helper_scripts</code>","text":""},{"location":"api/#SPTnano.helper_scripts.add_microns_and_secs","title":"<code>add_microns_and_secs(df, pixelsize_microns, time_between_frames)</code>","text":"<p>Adds columns to the DataFrame with positions in microns and time in seconds</p> Source code in <code>src/SPTnano/helper_scripts.py</code> <pre><code>def add_microns_and_secs(df, pixelsize_microns, time_between_frames):\n    '''Adds columns to the DataFrame with positions in microns and time in seconds'''\n    #space transformations\n    df['x_um'] = df['x'] * pixelsize_microns\n    df['y_um'] = df['y'] * pixelsize_microns\n\n    df['frame_zeroed'] = df.groupby('particle')['frame'].transform(lambda x: x - x.iloc[0])\n    df['time_s'] = df['frame'] * time_between_frames\n    df['time_s_zeroed'] = df.groupby('particle')['time_s'].transform(lambda x: x - x.iloc[0])\n    return df\n</code></pre>"},{"location":"api/#SPTnano.helper_scripts.filter_high_speeds","title":"<code>filter_high_speeds(metrics_df, speed_threshold)</code>","text":"<p>Filter based on speed instead - can be relevant if you have different exposure times and different times between frames</p> Source code in <code>src/SPTnano/helper_scripts.py</code> <pre><code>def filter_high_speeds(metrics_df, speed_threshold):\n    '''\n    Filter based on speed instead - can be relevant if you have different exposure times and different times between frames\n    '''\n\n    # Identify unique_ids with any high speeds\n    high_speed_particles = metrics_df[metrics_df['speed_um_s'] &gt; speed_threshold]['unique_id'].unique()\n\n    # Filter out particles with high speeds\n    metrics_df_filtered = metrics_df[~metrics_df['unique_id'].isin(high_speed_particles)].copy()\n    return metrics_df_filtered\n</code></pre>"},{"location":"api/#SPTnano.helper_scripts.filter_large_jumps","title":"<code>filter_large_jumps(df, threshold)</code>","text":"<p>Filter out entire particles with any frames showing large jumps in micrometers.</p>"},{"location":"api/#SPTnano.helper_scripts.filter_large_jumps--parameters","title":"Parameters","text":"<p>df : DataFrame     DataFrame containing tracking data with a 'segment_len_um' column. threshold : float     Threshold for what constitutes a large jump in micrometers.</p>"},{"location":"api/#SPTnano.helper_scripts.filter_large_jumps--returns","title":"Returns","text":"<p>DataFrame     DataFrame with particles having large jumps filtered out.</p> Source code in <code>src/SPTnano/helper_scripts.py</code> <pre><code>def filter_large_jumps(df, threshold):\n    \"\"\"\n    Filter out entire particles with any frames showing large jumps in micrometers.\n\n    Parameters\n    ----------\n    df : DataFrame\n        DataFrame containing tracking data with a 'segment_len_um' column.\n    threshold : float\n        Threshold for what constitutes a large jump in micrometers.\n\n    Returns\n    -------\n    DataFrame\n        DataFrame with particles having large jumps filtered out.\n    \"\"\"\n    # Identify unique_ids with any large jumps\n    large_jump_particles = df[df['segment_len_um'] &gt; threshold]['unique_id'].unique()\n\n    # Filter out particles with large jumps\n    df_filtered = df[~df['unique_id'].isin(large_jump_particles)].copy()\n    # df_filtered.drop(columns=['x_um_prev', 'y_um_prev', 'segment_len_um'], inplace=True)\n    return df_filtered\n</code></pre>"},{"location":"api/#SPTnano.helper_scripts.filter_stubs","title":"<code>filter_stubs(df, min_time)</code>","text":"<p>Removes tracks that are shorter than 'min_time' by finding the max duration of each time_s_zeroed column and filtering on that Works across exposure times, because it works on converted seconds, not frames</p> Source code in <code>src/SPTnano/helper_scripts.py</code> <pre><code>def filter_stubs(df, min_time):\n\n    '''\n    Removes tracks that are shorter than 'min_time' by finding the max duration of each time_s_zeroed column and filtering on that\n    Works across exposure times, because it works on converted seconds, not frames\n\n    '''\n    # Calculate the duration of each track by grouping by 'particle' and using the 'time_s' column\n    track_durations = df.groupby('unique_id')['time_s_zeroed'].max() \n    # Identify particles with tracks longer than 0.2 seconds\n    valid_particles = track_durations[track_durations &gt;= min_time].index\n    # Filter the dataframe to include only valid particles\n    filtered_df = df[df['unique_id'].isin(valid_particles)]\n\n    return filtered_df\n</code></pre>"},{"location":"api/#SPTnano.visualization","title":"<code>visualization</code>","text":""},{"location":"api/#SPTnano.visualization.batch_plot_trajectories","title":"<code>batch_plot_trajectories(master_folder, traj_df, batch=True, filename=None, colorby='particle', mpp=None, label=False, cmap=None)</code>","text":"<p>Batch plot trajectories for all replicates across several conditions.</p>"},{"location":"api/#SPTnano.visualization.batch_plot_trajectories--parameters","title":"Parameters","text":"<p>master_folder : str     Path to the master folder containing 'data' and 'saved_data' folders. traj_df : DataFrame     The DataFrame containing trajectory data. batch : bool, optional     If True, plots trajectories for all replicates in batch mode.     If False, plots trajectory for the specified filename. filename : str, optional     Filename of interest when batch is False. colorby : str, optional     Color by 'particle' or 'frame'. mpp : float, optional     Microns per pixel. label : bool, optional     Set to True to write particle ID numbers next to trajectories. cmap : colormap, optional     Colormap to use for coloring tracks.</p> Source code in <code>src/SPTnano/visualization.py</code> <pre><code>def batch_plot_trajectories(master_folder, traj_df, batch=True, filename=None, colorby='particle', mpp=None, label=False, cmap=None):\n    \"\"\"\n    Batch plot trajectories for all replicates across several conditions.\n\n    Parameters\n    ----------\n    master_folder : str\n        Path to the master folder containing 'data' and 'saved_data' folders.\n    traj_df : DataFrame\n        The DataFrame containing trajectory data.\n    batch : bool, optional\n        If True, plots trajectories for all replicates in batch mode.\n        If False, plots trajectory for the specified filename.\n    filename : str, optional\n        Filename of interest when batch is False.\n    colorby : str, optional\n        Color by 'particle' or 'frame'.\n    mpp : float, optional\n        Microns per pixel.\n    label : bool, optional\n        Set to True to write particle ID numbers next to trajectories.\n    cmap : colormap, optional\n        Colormap to use for coloring tracks.\n    \"\"\"\n    data_folder = os.path.join(master_folder, 'data')\n    vis_folder = os.path.join(master_folder, 'visualization')\n    os.makedirs(vis_folder, exist_ok=True)\n\n    if batch:\n        for condition in os.listdir(data_folder):\n            condition_folder = os.path.join(data_folder, condition)\n            if os.path.isdir(condition_folder):\n                for file in os.listdir(condition_folder):\n                    if file.endswith('.tif'):\n                        filepath = os.path.join(condition_folder, file)\n                        subset_traj_df = traj_df[traj_df['filename'] == file]\n                        if not subset_traj_df.empty:\n                            frames = pims.open(filepath)\n                            frame = frames[0]\n                            fig, ax = plt.subplots()\n                            plot_trajectory(subset_traj_df, colorby=colorby, mpp=mpp, label=label, superimpose=frame, cmap=cmap, ax=ax)\n                            plt.savefig(os.path.join(vis_folder, f'{condition}_{file}.png'))\n                            plt.close(fig)\n    else:\n        if filename is not None:\n            filepath = os.path.join(data_folder, filename)\n            subset_traj_df = traj_df[traj_df['filename'] == filename]\n            if not subset_traj_df.empty:\n                frames = pims.open(filepath)\n                frame = frames[0]\n                fig, ax = plt.subplots()\n                plot_trajectory(subset_traj_df, colorby=colorby, mpp=mpp, label=label, superimpose=frame, cmap=cmap, ax=ax)\n                plt.show()\n        else:\n            print(\"Please provide a filename when batch is set to False.\")\n</code></pre>"},{"location":"api/#SPTnano.visualization.plot_histograms","title":"<code>plot_histograms(data_df, feature, bins=100, separate=None, xlimit=None, small_multiples=False, palette='colorblind')</code>","text":"<p>Plot histograms of a specified feature for each category in coltoseparate, with consistent binning.</p>"},{"location":"api/#SPTnano.visualization.plot_histograms--parameters","title":"Parameters","text":"<p>data_df : DataFrame     DataFrame containing track data with the specified feature and optionally a separating column. feature : str     The feature to plot histograms for. bins : int, optional     Number of bins for the histogram. Default is 100. coltoseparate : str, optional     Column to separate the data by. If None, all data will be plotted together. Default is None. xlimit : float, optional     Upper limit for the x-axis. Default is None. small_multiples : bool, optional     Whether to plot each category separately as small multiples. Default is False.</p> Source code in <code>src/SPTnano/visualization.py</code> <pre><code>def plot_histograms(data_df, feature, bins=100, separate=None, xlimit=None, small_multiples=False, palette='colorblind'):\n    \"\"\"\n    Plot histograms of a specified feature for each category in coltoseparate, with consistent binning.\n\n    Parameters\n    ----------\n    data_df : DataFrame\n        DataFrame containing track data with the specified feature and optionally a separating column.\n    feature : str\n        The feature to plot histograms for.\n    bins : int, optional\n        Number of bins for the histogram. Default is 100.\n    coltoseparate : str, optional\n        Column to separate the data by. If None, all data will be plotted together. Default is None.\n    xlimit : float, optional\n        Upper limit for the x-axis. Default is None.\n    small_multiples : bool, optional\n        Whether to plot each category separately as small multiples. Default is False.\n    \"\"\"\n    unique_categories = data_df[separate].unique() if separate else [None]\n    color_palette = sns.color_palette(palette, len(unique_categories))\n\n    if small_multiples and separate is not None:\n        num_categories = len(unique_categories)\n        fig, axes = plt.subplots(num_categories, 1, figsize=(20, 6 * num_categories), sharex=True)\n\n        if num_categories == 1:\n            axes = [axes]  # To handle the case with only one subplot\n\n        for i, category in enumerate(unique_categories):\n            subset = data_df[data_df[separate] == category]\n            subsetvalues = subset[feature]\n\n            max_value = subsetvalues.max()\n            bin_edges = np.linspace(0, max_value, bins + 1)\n\n            # Plot histogram\n            sns.histplot(subsetvalues, bins=bin_edges, kde=True, ax=axes[i], stat=\"percent\", color=color_palette[i])\n            axes[i].set_title(f'{category}', fontsize=14)\n\n            mean_value = subsetvalues.mean()\n            median_value = subsetvalues.median()\n            number_of_tracks = len(subset['unique_id'].unique())\n            axes[i].text(0.4, 0.6, f\"Mean: {mean_value:.2f}, Median: {median_value:.2f}, Tracks: {number_of_tracks}\", transform=axes[i].transAxes, fontsize=10)\n\n            if xlimit is not None:\n                axes[i].set_xlim(0, xlimit)\n            else:\n                axes[i].set_xlim(0, max_value)\n\n        plt.xlabel(f'{feature}', fontsize=12)\n        plt.tight_layout()\n        plt.show()\n\n    else:\n        plt.figure(figsize=(20, 12))\n        size = 10\n        multiplier = 2\n        sns.set_context(\"notebook\", rc={\"xtick.labelsize\": size * multiplier, \"ytick.labelsize\": size * multiplier})\n\n        max_value = data_df[feature].max()\n        bin_edges = np.linspace(0, max_value, bins + 1)\n\n        if separate is None:\n            subsetvalues = data_df[feature]\n\n            # Calculate percentage counts\n            counts, _ = np.histogram(subsetvalues, bins=bin_edges)\n            percentage_counts = (counts / counts.sum()) * 100\n\n            # Plot histogram\n            sns.histplot(subsetvalues, bins=bin_edges, kde=True, alpha=0.5, stat=\"percent\", color=color_palette[0])\n\n            mean_value = subsetvalues.mean()\n            median_value = subsetvalues.median()\n            plt.text(0.4, 0.6, f\"Overall: mean: {mean_value:.2f}, median: {median_value:.2f}\", transform=plt.gca().transAxes, fontsize=10 * multiplier)\n\n        else:\n            for i, category in enumerate(unique_categories):\n                subset = data_df[data_df[separate] == category]\n                subsetvalues = subset[feature]\n\n                # Calculate percentage counts\n                counts, _ = np.histogram(subsetvalues, bins=bin_edges)\n                percentage_counts = (counts / counts.sum()) * 100\n\n                # Plot histogram\n                sns.histplot(subsetvalues, bins=bin_edges, kde=True, label=category, alpha=0.5, stat=\"percent\", color=color_palette[i])\n\n                mean_value = subsetvalues.mean()\n                median_value = subsetvalues.median()\n                number_of_tracks = len(subset['unique_id'].unique())\n                shift = i * 0.05\n                plt.text(0.4, 0.6 - shift, f\"{category}: mean: {mean_value:.2f} from {number_of_tracks} tracks\", transform=plt.gca().transAxes, fontsize=10 * multiplier)\n\n        plt.xlabel(f'{feature}', fontsize=size * multiplier)\n        plt.ylabel('Percentage', fontsize=size * multiplier)\n        plt.legend(title='', fontsize=size * multiplier)\n        ax = plt.gca()\n        if xlimit is not None:\n            ax.set_xlim(0, xlimit)\n        else:\n            ax.set_xlim(0, max_value)\n        plt.show()\n</code></pre>"},{"location":"api/#SPTnano.visualization.plot_histograms_seconds","title":"<code>plot_histograms_seconds(traj_df, bins=100, coltoseparate='tracker', xlimit=None)</code>","text":"<p>Plot histograms of track lengths in seconds for each tracker, with consistent binning.</p>"},{"location":"api/#SPTnano.visualization.plot_histograms_seconds--parameters","title":"Parameters","text":"<p>traj_df : DataFrame     DataFrame containing track data with columns 'tracker', 'unique_id', 'time_s_zeroed', and 'filename'. bins : int, optional     Number of bins for the histogram. Default is 100. coltoseparate : str, optional     Column to separate the data by. Default is 'tracker'. xlimit : float, optional     Upper limit for the x-axis. Default is None.</p> Source code in <code>src/SPTnano/visualization.py</code> <pre><code>def plot_histograms_seconds(traj_df, bins=100, coltoseparate='tracker', xlimit=None):\n    \"\"\"\n    Plot histograms of track lengths in seconds for each tracker, with consistent binning.\n\n    Parameters\n    ----------\n    traj_df : DataFrame\n        DataFrame containing track data with columns 'tracker', 'unique_id', 'time_s_zeroed', and 'filename'.\n    bins : int, optional\n        Number of bins for the histogram. Default is 100.\n    coltoseparate : str, optional\n        Column to separate the data by. Default is 'tracker'.\n    xlimit : float, optional\n        Upper limit for the x-axis. Default is None.\n    \"\"\"\n    plt.figure(figsize=(20, 12))\n    size = 10\n    multiplier = 2\n    sns.set_context(\"notebook\", rc={\"xtick.labelsize\": size*multiplier, \"ytick.labelsize\": size*multiplier})\n\n    max_track_length = traj_df.groupby('unique_id')['time_s_zeroed'].max().max()\n    bin_edges = np.linspace(0, max_track_length, bins + 1)\n\n    for i, tracker in enumerate(traj_df[coltoseparate].unique()):\n        subset = traj_df[traj_df[coltoseparate] == tracker]\n        subsetvalues = subset.groupby('unique_id')['time_s_zeroed'].max()\n\n        # Calculate percentage counts\n        counts, _ = np.histogram(subsetvalues, bins=bin_edges)\n        percentage_counts = (counts / counts.sum()) * 100\n\n        # Plot histogram\n        sns.histplot(subsetvalues, bins=bin_edges, kde=True, label=tracker, alpha=0.5, stat=\"percent\")\n\n        subset_mean = subsetvalues.mean()\n        subset_median = subsetvalues.median()\n        subset_number_of_tracks = len(subset['unique_id'].unique())\n        shift = i * 0.05\n        plt.text(0.4, 0.6 - shift, f\"{tracker}: mean: {subset_mean:.2f} seconds from {subset_number_of_tracks} tracks\", transform=plt.gca().transAxes, fontsize=10 * multiplier)\n\n    plt.xlabel('Track length (seconds)', fontsize=size * multiplier)\n    plt.ylabel('Percentage', fontsize=size * multiplier)\n    plt.legend(title='', fontsize=size * multiplier)\n    ax = plt.gca()\n    if xlimit is not None:\n        ax.set_xlim(0, xlimit)\n    else:\n        ax.set_xlim(0, max_track_length)\n    plt.show()\n</code></pre>"},{"location":"api/#SPTnano.visualization.plot_trajectory","title":"<code>plot_trajectory(traj, colorby='particle', mpp=None, label=False, superimpose=None, cmap=None, ax=None, t_column=None, pos_columns=None, plot_style={}, **kwargs)</code>","text":"<p>Plot traces of trajectories for each particle. Optionally superimpose it on a frame from the video.</p>"},{"location":"api/#SPTnano.visualization.plot_trajectory--parameters","title":"Parameters","text":"<p>traj : DataFrame     The DataFrame should include time and spatial coordinate columns. colorby : {'particle', 'frame'}, optional mpp : float, optional     Microns per pixel. If omitted, the labels will have units of pixels. label : boolean, optional     Set to True to write particle ID numbers next to trajectories. superimpose : ndarray, optional     Background image, default None cmap : colormap, optional     This is only used in colorby='frame' mode. Default = mpl.cm.winter ax : matplotlib axes object, optional     Defaults to current axes t_column : string, optional     DataFrame column name for time coordinate. Default is 'frame'. pos_columns : list of strings, optional     Dataframe column names for spatial coordinates. Default is ['x', 'y']. plot_style : dictionary     Keyword arguments passed through to the <code>Axes.plot(...)</code> command</p>"},{"location":"api/#SPTnano.visualization.plot_trajectory--returns","title":"Returns","text":"<p>Axes object</p> Source code in <code>src/SPTnano/visualization.py</code> <pre><code>def plot_trajectory(traj, colorby='particle', mpp=None, label=False,\n                    superimpose=None, cmap=None, ax=None, t_column=None,\n                    pos_columns=None, plot_style={}, **kwargs):\n    \"\"\"\n    Plot traces of trajectories for each particle.\n    Optionally superimpose it on a frame from the video.\n\n    Parameters\n    ----------\n    traj : DataFrame\n        The DataFrame should include time and spatial coordinate columns.\n    colorby : {'particle', 'frame'}, optional\n    mpp : float, optional\n        Microns per pixel. If omitted, the labels will have units of pixels.\n    label : boolean, optional\n        Set to True to write particle ID numbers next to trajectories.\n    superimpose : ndarray, optional\n        Background image, default None\n    cmap : colormap, optional\n        This is only used in colorby='frame' mode. Default = mpl.cm.winter\n    ax : matplotlib axes object, optional\n        Defaults to current axes\n    t_column : string, optional\n        DataFrame column name for time coordinate. Default is 'frame'.\n    pos_columns : list of strings, optional\n        Dataframe column names for spatial coordinates. Default is ['x', 'y'].\n    plot_style : dictionary\n        Keyword arguments passed through to the `Axes.plot(...)` command\n\n    Returns\n    -------\n    Axes object\n    \"\"\"\n    if cmap is None:\n        cmap = plt.cm.winter\n    if t_column is None:\n        t_column = 'frame'\n    if pos_columns is None:\n        pos_columns = ['x', 'y']\n    if len(traj) == 0:\n        raise ValueError(\"DataFrame of trajectories is empty.\")\n\n    _plot_style = dict(linewidth=1)\n    _plot_style.update(**plot_style)\n\n    if ax is None:\n        ax = plt.gca()\n\n    # Axes labels\n    if mpp is None:\n        ax.set_xlabel(f'{pos_columns[0]} [px]')\n        ax.set_ylabel(f'{pos_columns[1]} [px]')\n        mpp = 1.  # for computations of image extent below\n    else:\n        ax.set_xlabel(f'{pos_columns[0]} [\u03bcm]')\n        ax.set_ylabel(f'{pos_columns[1]} [\u03bcm]')\n\n    # Background image\n    if superimpose is not None:\n        ax.imshow(superimpose, cmap=plt.cm.gray,\n                  origin='lower', interpolation='nearest',\n                  vmin=kwargs.get('vmin'), vmax=kwargs.get('vmax'))\n        ax.set_xlim(-0.5 * mpp, (superimpose.shape[1] - 0.5) * mpp)\n        ax.set_ylim(-0.5 * mpp, (superimpose.shape[0] - 0.5) * mpp)\n\n    # Trajectories\n    if colorby == 'particle':\n        # Unstack particles into columns.\n        unstacked = traj.set_index(['particle', t_column])[pos_columns].unstack()\n        for i, trajectory in unstacked.iterrows():\n            ax.plot(mpp * trajectory[pos_columns[0]], mpp * trajectory[pos_columns[1]], **_plot_style)\n    elif colorby == 'frame':\n        # Read http://www.scipy.org/Cookbook/Matplotlib/MulticoloredLine\n        x = traj.set_index([t_column, 'particle'])[pos_columns[0]].unstack()\n        y = traj.set_index([t_column, 'particle'])[pos_columns[1]].unstack()\n        color_numbers = traj[t_column].values / float(traj[t_column].max())\n        for particle in x:\n            points = np.array([x[particle].values, y[particle].values]).T.reshape(-1, 1, 2)\n            segments = np.concatenate([points[:-1], points[1:]], axis=1)\n            lc = LineCollection(segments, cmap=cmap)\n            lc.set_array(color_numbers)\n            ax.add_collection(lc)\n            ax.set_xlim(x.apply(np.min).min(), x.apply(np.max).max())\n            ax.set_ylim(y.apply(np.min).min(), y.apply(np.max).max())\n\n    if label:\n        unstacked = traj.set_index([t_column, 'particle'])[pos_columns].unstack()\n        first_frame = int(traj[t_column].min())\n        coords = unstacked.fillna(method='backfill').stack().loc[first_frame]\n        for particle_id, coord in coords.iterrows():\n            ax.text(*coord.tolist(), s=\"%d\" % particle_id,\n                    horizontalalignment='center',\n                    verticalalignment='center')\n\n    ax.invert_yaxis()\n    return ax\n</code></pre>"}]}