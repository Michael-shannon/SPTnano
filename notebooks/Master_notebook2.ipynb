{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master notebook 6/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, unicode_literals, print_function  # for compatibility with Python 2 and 3\n",
    "import sys\n",
    "sys.path.append('../src')  # Adjust the path as necessary\n",
    "\n",
    "from SPTnano import ROISelector, process_directory, generate_file_tree, display_file_tree, overlay_tracks_with_movie, plot_histograms\n",
    "\n",
    "# from SPTnano import ROISelector, process_directory\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series  # for convenience\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "import os\n",
    "import glob\n",
    "import nd2\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the file tree\n",
    "display_file_tree('D:\\GITHUB_SOFTWARE\\SPTnano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the following to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Optionally, tweak styles.\n",
    "mpl.rc('figure',  figsize=(10, 5))\n",
    "mpl.rc('image', cmap='gray')\n",
    "\n",
    "sns.set_context(\"notebook\", rc={\"xtick.labelsize\": 10, \"ytick.labelsize\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2files = 'D:/6-25-2024_trackercomparison/ND2_test_data/'\n",
    "master = 'D:/6-25-2024_trackercomparison/raw_data_notinverted/'\n",
    "saved_data_dir = 'D:/6-25-2024_trackercomparison/TrackPy_notinverted_Ultra100ms/'\n",
    "\n",
    "# Use glob to find TIF files in the directory and its subdirectories\n",
    "tif_files = glob.glob(saved_data_dir + '**/*.tif', recursive=True)\n",
    "# Print the list of TIF files\n",
    "print(tif_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: crop ND2 images and make into tiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the ROI size\n",
    "roi_width = 150\n",
    "roi_height = 150\n",
    "\n",
    "# Run the function to process the directory\n",
    "# batch_roi_selector.process_directory(nd2_directory, tif_directory, roi_width, roi_height) #\n",
    "process_directory(nd2files, master, roi_width, roi_height) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main pytrack pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = pims.open(tif_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_circle_size = 7 # in SLIMfast this was 13 for 10 ms\n",
    "f = tp.locate(frames[0], detection_circle_size, invert=False)\n",
    "tp.annotate(f, frames[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(f['mass'], bins=20)\n",
    "\n",
    "# Optionally, label the axes.\n",
    "ax.set(xlabel='mass', ylabel='count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tp.locate(frames[0], 7, invert=False, minmass=150)\n",
    "tp.annotate(f, frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.subpx_bias(tp.locate(frames[2], 7, invert=False, minmass=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tp.batch(frames[:], 7, minmass=150, invert=False, engine='numba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp.quiet()  # Turn off progress reports for best performance\n",
    "linking_max_distance = 10\n",
    "disappearance_max_frames = 0\n",
    "t = tp.link(f, linking_max_distance, memory=disappearance_max_frames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(t.particle.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tp.filter_stubs(t, 2) # for 100 ms data, 2 frames is 0.2 seconds. In tiago's SLIMfast data, this was 5 frames at 10 ms, which is 50 ms. As a track is not a track unless it has 2 frames, this is the minimal value we can put.\n",
    "minimum_track_length = 2\n",
    "# Compare the number of particles in the unfiltered and filtered data.\n",
    "print('Before:', t['particle'].nunique())\n",
    "print('After:', t1['particle'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "tp.mass_size(t1.groupby('particle').mean()); # convenience function -- just plots size vs. mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "tp.annotate(t[t['frame'] == 0], frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "tp.annotate(t1[t1['frame'] == 0], frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ecc as a histogram\n",
    "plt.figure()\n",
    "t1['ecc'].hist(bins=100)\n",
    "plt.xlabel('eccentricity')\n",
    "plt.ylabel('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "tp.annotate(t2[t2['frame'] == 0], frames[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH TRACKPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### detection settings ######## FOR 100 ms!!! #######\n",
    "\n",
    "detection_circle_size = 7 # set for 100 ms\n",
    "minimum_intensity = 150 # set for 100 ms\n",
    "iterations = 50\n",
    "svn_threshold = 10\n",
    "noise_size = 1.01017\n",
    "engine = 'numba'\n",
    "\n",
    "####### linking settings ########\n",
    "linking_max_distance = 7\n",
    "disappearance_max_frames = 2\n",
    "\n",
    "####### filtering settings ########\n",
    "minimum_track_length = 5\n",
    "\n",
    "size = 2\n",
    "\n",
    "# Create an empty master dataframe\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "# Drift correction\n",
    "drift_correction = False\n",
    "# filtering needed?\n",
    "filtering = False\n",
    "\n",
    "tp.quiet()  # Turn off progress reports for best performance\n",
    "for i in range(len(tif_files)):\n",
    "    frames = pims.open(tif_files[i])\n",
    "    f = tp.batch(frames[:], detection_circle_size, minmass=minimum_intensity, invert=True, max_iterations=iterations, threshold=svn_threshold)\n",
    "    t = tp.link(f, linking_max_distance, memory=disappearance_max_frames)\n",
    "    t1 = tp.filter_stubs(t, minimum_track_length)\n",
    "    print('Before:', t['particle'].nunique())\n",
    "    print('After:', t1['particle'].nunique())\n",
    "    if filtering == True:\n",
    "        t2 = t1[((t1['mass'] > minimum_intensity) & (t1['size'] < size))]\n",
    "    else:\n",
    "        t2 = t1.copy()\n",
    "    if drift_correction == True:\n",
    "        d = tp.compute_drift(t2)\n",
    "        tm = tp.subtract_drift(t2.copy(), d)\n",
    "    else:\n",
    "        tm=t2.copy()\n",
    "    # Add column with the filename\n",
    "    tm['filename'] = os.path.splitext(os.path.basename(tif_files[i]))[0]\n",
    "    # Append tm dataframe to the master dataframe\n",
    "    master_df = pd.concat([master_df, tm])\n",
    "\n",
    "    # tm.to_csv(tif_files[i] + '.csv')\n",
    "    print(tif_files[i] + ' processed')\n",
    "    print('-------------------------------------')\n",
    "    # reset index\n",
    "master_df = master_df.reset_index(drop=True)\n",
    "# create a file ID (integer) based on each filename\n",
    "master_df['file_id'] = pd.Categorical(master_df['filename']).codes\n",
    "# # create a uniq_id for each particle, based on the filename and the particle number\n",
    "master_df['unique_id'] = master_df['file_id'].astype(str) + '_' + master_df['particle'].astype(str)\n",
    "\n",
    "master_df.to_csv(saved_data_dir + 'master_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the master_df\n",
    "master_df = pd.read_csv(saved_data_dir + 'master_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random number from the unique particles\n",
    "random_particle = np.random.choice(master_df['particle'].unique())\n",
    "\n",
    "# extract a new 'particle df' for a random particle\n",
    "\n",
    "\n",
    "particle_df = master_df[master_df['particle'] == random_particle]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of frames for each particle\n",
    "frame_counts = master_df['unique_id'].value_counts()\n",
    "\n",
    "# Compute the mean track length across all particles\n",
    "mean_track_length_value_counts = frame_counts.mean()\n",
    "median_track_length_value_counts = frame_counts.median()\n",
    "\n",
    "print('Mean track length: ' + str(mean_track_length_value_counts))\n",
    "print('Median track length: ' + str(median_track_length_value_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIMfast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))  # Set the figure size to create a square plot\n",
    "# extract a df for each filename\n",
    "filenames = SLIMfast_df['filename'].unique()\n",
    "print(filenames)\n",
    "picked_filename = filenames[3]\n",
    "df = SLIMfast_df[SLIMfast_df['filename'] == picked_filename]\n",
    "\n",
    "\n",
    "f = tp.plot_traj(df)\n",
    "# add title to f\n",
    "f.set_title(picked_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie function. Takes the current tracks_df and the full movie path you want to convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets the tracks_df and movie path. Input is the name of the file you want to make a movie for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Possible filenames are: {master_df[\"filename\"].unique()}')\n",
    "\n",
    "filename = 'RUES2_kinesinhaloJFX554_laser25_009_cropped'\n",
    "tracks_df = master_df[master_df['filename'] == filename]\n",
    "tracks_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "directory = os.path.dirname(tif_files[0])\n",
    "# print(directory)\n",
    "# \n",
    "movie_path = os.path.join(directory, filename + '.tif')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIMfast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Possible filenames are: {SLIMfast_df[\"filename\"].unique()}')\n",
    "\n",
    "filename = 'RUES2_kinesinhaloJFX554_laser25_009_cropped_tracked'\n",
    "tracks_df = SLIMfast_df[SLIMfast_df['filename'] == filename]\n",
    "tracks_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "directory = os.path.dirname(SLIMfastdatapath[0])\n",
    "print(directory)\n",
    "print(SLIMfastdatapath)\n",
    "# # \n",
    "# movie_path = os.path.join(SLIMfastdatapath, filename + '.tif')    \n",
    "# print(movie_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_tracks_with_movie(tracks_df, movie_path, colormap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIMfast data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIMfastdatapath='D:/6-25-2024_trackercomparison/SLIMfast_notinverted_Ultra100ms/Condition_100msUltra_matchedwithtrackpy_1poin2searchfactor_trackedexport/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIMfastdatapath='D:/6-25-2024_trackercomparison/SLIMfast_notinverted_Ultra100ms/Condition_100msUltra_matchedwithtrackpy_1poin2searchfactor_trackedexport/'\n",
    "# list files\n",
    "files = os.listdir(SLIMfastdatapath)\n",
    "SLIMfast_df = pd.DataFrame()\n",
    "Colnames = ['x', 'y', 'frame', 'particle', 'factor1', 'factor2', 'factor3', 'factor4',]\n",
    "\n",
    "for file in files:\n",
    "    # print(file)\n",
    "    df = pd.read_csv(SLIMfastdatapath + file, sep='\\t', names=Colnames)\n",
    "\n",
    "    df['filename'] = os.path.splitext(os.path.basename(file))[0]\n",
    "# Append tm dataframe to the master dataframe\n",
    "    SLIMfast_df = pd.concat([SLIMfast_df, df])\n",
    "\n",
    "\n",
    "SLIMfast_df = SLIMfast_df.reset_index(drop=True)\n",
    "# create a file ID (integer) based on each filename\n",
    "SLIMfast_df['file_id'] = pd.Categorical(SLIMfast_df['filename']).codes\n",
    "# # create a uniq_id for each particle, based on the filename and the particle number\n",
    "SLIMfast_df['unique_id'] = SLIMfast_df['file_id'].astype(str) + '_' + SLIMfast_df['particle'].astype(str)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIMfast_df.to_csv(SLIMfastdatapath + 'SLIMfast_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load both dfs\n",
    "master_df = pd.read_csv(saved_data_dir + 'master_df.csv')\n",
    "SLIMfast_df = pd.read_csv(SLIMfastdatapath + 'SLIMfast_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIMfast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Glorious - you now have a SLIMfast_df and a master_df == trackpy_df. You could easily make a histogram.\n",
    "\n",
    "# The movies from here - can you check what the matlab code does, in order to cut off the tracks that have disappeared? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Assuming 'master_df' has a 'filename' column and 'unique_id' for track lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Loop through each unique filename and plot its histogram\n",
    "for i, filename in enumerate(master_df['filename'].unique()):\n",
    "    subset = master_df[master_df['filename'] == filename]\n",
    "    file_id = subset['file_id'].unique()\n",
    "    # add 1 to file_id to make it human readable and remove the []\n",
    "    file_id = file_id[0] + 1\n",
    "\n",
    "    shift = i * 0.05\n",
    "    sns.histplot(subset['unique_id'].value_counts(), kde=True, bins=100, label=filename, alpha=0.5)\n",
    "    subset_mean = subset['unique_id'].value_counts().mean()\n",
    "    subset_median = subset['unique_id'].value_counts().median()\n",
    "    subset_number_of_tracks = len(subset['unique_id'].unique())\n",
    "    plt.text(0.5, 0.7-shift, f\"{file_id}: mean: {subset_mean:.2f} frames from {subset_number_of_tracks} tracks\", transform=plt.gca().transAxes)\n",
    "\n",
    "plt.xlabel('Track length (frames)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Filename')\n",
    "plt.title('Overlaid Histograms by Filename')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackPy_df = master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DATAFRAME PRUNING AND CONCATENATION ######\n",
    "\n",
    "# Add a column that just says trackpy in every row of the TrackPy_df\n",
    "TrackPy_df['tracker'] = 'TrackPy'\n",
    "# same with slimfast\n",
    "SLIMfast_df['tracker'] = 'SLIMfast'\n",
    "# concatenate the two dataframes\n",
    "\n",
    "# get columns names of the two dataframes\n",
    "print(TrackPy_df.columns)\n",
    "print(SLIMfast_df.columns)\n",
    "\n",
    "# remove all of the columns apart from x, y, frame, particle, filename, unique_id, tracker, file id\n",
    "TrackPy_df_sub = TrackPy_df[['x', 'y', 'frame', 'particle', 'filename', 'unique_id', 'tracker', 'file_id']]\n",
    "SLIMfast_df_sub = SLIMfast_df[['x', 'y', 'frame', 'particle', 'filename', 'unique_id', 'tracker', 'file_id']]\n",
    "\n",
    "# concatenate the two dataframes\n",
    "combined_df = pd.concat([TrackPy_df_sub, SLIMfast_df_sub])\n",
    "\n",
    "# save it\n",
    "combined_df.to_csv(saved_data_dir + 'combined_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "framerate = 0.1 #seconds per frame\n",
    "# value counts of the unique_id\n",
    "valuecountstrackpy = TrackPy_df['unique_id'].value_counts()\n",
    "valuecountsslimfast = SLIMfast_df['unique_id'].value_counts()\n",
    "# print(valuecounts)\n",
    "# translate each value count to time in seconds by multiplying by 0.1\n",
    "valuecounts_secondstrackpy = valuecountstrackpy * framerate\n",
    "valuecounts_secondsslimfast = valuecountsslimfast * framerate\n",
    "# valuecounts_seconds\n",
    "\n",
    "sns.histplot(valuecounts_seconds, kde=True, bins = 100)\n",
    "plt.xlabel('Track length (seconds)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Annotate plot with mean and median\n",
    "mean = valuecounts_seconds.mean()\n",
    "median = valuecounts_seconds.median()\n",
    "plt.text(0.5, 0.9, f\"Mean: {mean:.2f} seconds\", transform=plt.gca().transAxes)\n",
    "plt.text(0.5, 0.85, f\"Median: {median:.2f} seconds\", transform=plt.gca().transAxes)\n",
    "plt.text(0.5, 0.8, f\"Number of tracks: {len(master_df['unique_id'].unique())}\", transform=plt.gca().transAxes)\n",
    "\n",
    "plt.show()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framerate = 0.1 #seconds per frame\n",
    "\n",
    "# Assuming 'master_df' has a 'filename' column and 'unique_id' for track lengths\n",
    "plt.figure(figsize=(20, 12))\n",
    "size=10\n",
    "multiplier = 2\n",
    "sns.set_context(\"notebook\", rc={\"xtick.labelsize\": size*multiplier, \"ytick.labelsize\": size*multiplier})\n",
    "\n",
    "# Loop through each unique filename and plot its histogram\n",
    "for i, tracker in enumerate(combined_df['tracker'].unique()):\n",
    "    subset = combined_df[combined_df['tracker'] == tracker]\n",
    "    subsetvalues = subset['unique_id'].value_counts()\n",
    "    subsetvalues_seconds = subsetvalues * framerate\n",
    "    # make these into a percentage of the total number of tracks\n",
    "\n",
    "\n",
    "    shift = i * 0.05\n",
    "    sns.histplot(subsetvalues_seconds, kde=True, stat='percent', bins=100, label=tracker, alpha=0.5, )\n",
    "    subset_mean = subsetvalues_seconds.mean()\n",
    "    subset_median = subsetvalues_seconds.median()\n",
    "    subset_number_of_tracks = len(subset['unique_id'].unique())\n",
    "    plt.text(0.55, 0.8-shift, f\"{tracker}: mean: {subset_mean:.2f} seconds from {subset_number_of_tracks} tracks\", transform=plt.gca().transAxes, fontsize=10*multiplier)\n",
    "\n",
    "plt.xlabel('Track length (seconds)', fontsize=size*multiplier)\n",
    "plt.ylabel('Percentage', fontsize=size*multiplier)\n",
    "plt.legend(title='', fontsize=size*multiplier)\n",
    "# Get the current axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set the x-axis and y-axis limits\n",
    "# ax.set_xlim(0, 10)  # Set the x-axis limits\n",
    "# ax.set_ylim(0, 30)   # Set the y-axis limits\n",
    "# plt.title('Overlaid Histograms by Tracker')\n",
    "plt.show()\n",
    "\n",
    "# increase the resolution ofe the plot\n",
    "# plt.figure(figsize=(10, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does trackpy have tracks shorter than 5 frames?\n",
    "# Does SLIMfast have tracks shorter than 5 frames?\n",
    "# calculate\n",
    "# value counts of the unique_id\n",
    "valuecountstrackpy = TrackPy_df['unique_id'].value_counts()\n",
    "valuecountsslimfast = SLIMfast_df['unique_id'].value_counts()\n",
    "print(min(valuecountstrackpy))\n",
    "print(min(valuecountsslimfast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))  # Set the figure size to create a square plot\n",
    "# extract a df for each filename\n",
    "filenames = master_df['filename'].unique()\n",
    "print(filenames)\n",
    "picked_filename = filenames[3]\n",
    "df = master_df[master_df['filename'] == picked_filename]\n",
    "\n",
    "\n",
    "f = tp.plot_traj(df)\n",
    "# add title to f\n",
    "f.set_title(picked_filename)\n",
    "\n",
    "\n",
    "# plt.axis('equal')  # Set the aspect ratio to be equal\n",
    "# make the title the filename\n",
    "# plt.title(filenames[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to replace tps plotting one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(combined_df, framerate=0.1, bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
