{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, unicode_literals, print_function  # for compatibility with Python 2 and 3\n",
    "import sys\n",
    "sys.path.append('../src')  # Adjust the path as necessary\n",
    "# sys.path.append('..')  # Adjust the path as necessary\n",
    "\n",
    "# from SPTnano import ROISelector, process_directory, generate_file_tree, display_file_tree, overlay_tracks_with_movie, plot_histograms,  read_mat_file, add_microns_and_secs, add_unique_id, plot_particle_trajectory, plot_multiple_particles, filter_stubs\n",
    "import SPTnano as spt\n",
    "# from SPTnano import ROISelector, process_directory\n",
    "\n",
    "master = spt.config.MASTER\n",
    "saved_data = spt.config.SAVED_DATA\n",
    "\n",
    "# import pixel size and frame rate\n",
    "pixelsize_microns = spt.config.PIXELSIZE_MICRONS\n",
    "time_between_frames = spt.config.TIME_BETWEEN_FRAMES\n",
    "orderofconditions = spt.config.ORDEROFCONDITIONS\n",
    "features = spt.config.FEATURES\n",
    "\n",
    "min_track_length = spt.config.TIME_WINDOW\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series  # for convenience\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "import os\n",
    "import glob\n",
    "import nd2\n",
    "import seaborn as sns\n",
    "\n",
    "# change the following to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Optionally, tweak styles.\n",
    "mpl.rc('figure',  figsize=(10, 5))\n",
    "mpl.rc('image', cmap='gray')\n",
    "\n",
    "sns.set_context(\"notebook\", rc={\"xtick.labelsize\": 10, \"ytick.labelsize\": 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPTnano.batch_roi_selector import ROISelector  # Adjust 'your_module' to your actual module name\n",
    "\n",
    "# Paths\n",
    "\n",
    "\n",
    "input_directory = master  # Directory where your actual ND2/TIFF image data is stored\n",
    "# output_directory = 'D:/Neurons_HTT_September_2024/9-11-2024_neurons_100x_25perc_10ms_20H20Scortandvent_150H20Scortandvent_analyze10'  # Directory to save the cropped images\n",
    "# output_directory = 'D:/PLURIPOTENT_KINESIN_JULY_2024/10ms_60x_kinesin_pluripotent_priorityone_analyze' \n",
    "# output_directory = 'D:/2_5_2025and2_7_2025_corticalneurons_analyze'\n",
    "# output_directory = 'D:/2_25_2025_CorticalNeuron_20H20S_FreeHalo_20H77S_77H20S_analyze'\n",
    "\n",
    "# output_directory = 'D:/2_21_2025_KinesinEScells_RUES2_HTT72CAG_HTTKO_10ms_analyze'\n",
    "\n",
    "# output_directory = 'D:/3_4_2025_CorticalNeuron_20H20S_freehalo_20H77S_77H20S_analyze'\n",
    "\n",
    "# output_directory = 'D:/3_11_2025_VentralNeuron_20H20S_freehalo_77H20S_20H77S_analyze'\n",
    "# output_directory = 'D:/3_13_2025_KinesininES_TN_RUES2_CAG72_KO_10ms_analyze'\n",
    "# output_directory = 'D:/3_13_2025_ES_KinesinAB_RUES2_CAG72_KO_10ms_analyze'\n",
    "output_directory = 'D:/4_26_2025_Kinesininneurons_cort_analyze'\n",
    "\n",
    "# metadata_csv_path = 'D:/DENOISING/FromMetadata_test/metadata_summary.csv'\n",
    "# metadata_csv_path = 'D:/DENOISING/DarkFrameCorrectionTest/metadata_summary.csv'\n",
    "\n",
    "metadata_csv_path = 'D:/SAVED/metadata_summaryrah.csv'\n",
    "\n",
    "\n",
    "# dark_frame_directory = 'D:/Darkframes100ms'\n",
    "dark_frame_directory = 'D:/Darkframes10ms'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize ROISelector with metadata-enabled selection\n",
    "selector = ROISelector(\n",
    "    input_directory=input_directory,\n",
    "    output_directory=output_directory,\n",
    "    roi_width=150,  # Use the width from your ROI metadata\n",
    "    roi_height=150,  # Use the height from your ROI metadata\n",
    "    split_tiff=False,  # Set as per your needs\n",
    "    dark_frame_subtraction=True,  # Enable dark frame subtraction if needed\n",
    "    dark_frame_directory=dark_frame_directory,\n",
    "    save_dark_corrected=False,  # Save dark-corrected images\n",
    "    ROI_from_metadata=False,  # Enable ROI selection from metadata\n",
    "    percentile_correction=True,\n",
    "    metadata_path=metadata_csv_path,  # Provide path to the metadata CSV file\n",
    "    pmin=1\n",
    ")\n",
    "\n",
    "# Prepare folders and process conditions\n",
    "selector.prepare_output_folders()\n",
    "selector.process_conditions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Walk through the directory structure\n",
    "for dirpath, dirnames, filenames in os.walk(master):\n",
    "    # print(dirpath)\n",
    "    # print(dirnames)\n",
    "    # print(filenames)\n",
    "    for filename in filenames:\n",
    "        # print(filename)\n",
    "        if filename.endswith('_tracked.mat'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            # print(file_path)\n",
    "            df = spt.read_mat_file(file_path)\n",
    "            # print(file_path)\n",
    "            # Add a column for the condition and file identifier\n",
    "            # condition = os.path.basename(os.path.dirname(os.path.dirname(file_path)))\n",
    "            condition = os.path.basename(os.path.dirname(file_path))\n",
    "\n",
    "\n",
    "            identifier = os.path.splitext(filename)[0]\n",
    "            df['condition'] = condition\n",
    "            df['filename'] = identifier\n",
    "            #### If you want to get the ms from the condition name, use below ####\n",
    "            # extract the part of the condition name after the last underscore\n",
    "            # condition_name = condition.split('_')[-1]\n",
    "            # # remove the ms from the condition name\n",
    "            # condition_name = condition_name.replace('ms', '')\n",
    "            # time_between_frames = int(condition_name) / 1000\n",
    "            # print(time_between_frames)\n",
    "            #### If you want to get the ms from the condition name, use above ####\n",
    "            df = spt.add_microns_and_secs(df, pixelsize_microns, time_between_frames)\n",
    "            dataframes.append(df)\n",
    "\n",
    "# # Concatenate all DataFrames into a single DataFrame\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "df = spt.add_unique_id(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unique_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter the short tracks out!\n",
    "df_filtstubs = spt.filter_stubs(df, min_time=0.2) #0.6 for before, 0.2 now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just load filtstubs\n",
    "df_filtstubs = pd.read_csv(saved_data + 'df_filtstubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# # list of possible thresholds\n",
    "# # segment_length_thresholds = [0.95, 1.0, 1.05]\n",
    "\n",
    "\n",
    "\n",
    "# segment_length_threshold = 1.0 # segment length threshold in um. \n",
    "# print(segment_length_threshold)\n",
    "# min_track_length_seconds = 0.2  # Specify the minimum track duration in seconds\n",
    "# # time_between_frames = config.TIME_BETWEEN_FRAMES  # From config\n",
    "\n",
    "# # Run the cleaning function\n",
    "# cleaned_df, removed_unique_ids, report = spt.clean_and_split_tracks(\n",
    "#     df_filtstubs, \n",
    "#     segment_length_threshold=segment_length_threshold, \n",
    "#     min_track_length_seconds=min_track_length_seconds,\n",
    "#     time_between_frames=time_between_frames\n",
    "# )\n",
    "\n",
    "# # saved the cleaned df\n",
    "# cleaned_df.to_csv(saved_data + 'cleaned_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df_filtstubs\n",
    "df_filtstubs.to_csv(saved_data + 'df_filtstubs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfix_df = df_filtstubs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "# list of possible thresholds\n",
    "# segment_length_thresholds = [0.95, 1.0, 1.05]\n",
    "\n",
    "\n",
    "\n",
    "segment_length_threshold = 1.0 # segment length threshold in um. \n",
    "# segment_length_threshold = 0.3\n",
    "\n",
    "print(segment_length_threshold)\n",
    "min_track_length_seconds = 0.2  # Specify the minimum track duration in seconds\n",
    "# time_between_frames = config.TIME_BETWEEN_FRAMES  # From config\n",
    "\n",
    "# Run the cleaning function\n",
    "pathfix_df, pathfix_removed_unique_ids, pathfix_report = spt.pathfixer(\n",
    "    df_filtstubs, \n",
    "    segment_length_threshold=segment_length_threshold, \n",
    "    min_track_length_seconds=min_track_length_seconds,\n",
    "    time_between_frames=time_between_frames\n",
    ")\n",
    "\n",
    "# saved the cleaned df\n",
    "pathfix_df.to_csv(saved_data + 'cleaned_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW VERSION:\n",
    "\n",
    "# Create an instance of ParticleMetrics with your data and time_between_frames value\n",
    "particle_metrics = spt.ParticleMetrics(pathfix_df, time_between_frames)\n",
    "\n",
    "# Calculate all features, without calculating time-windowed metrics initially\n",
    "metrics_df = particle_metrics.calculate_all_features(calculate_time_windowed=False)\n",
    "\n",
    "# Specify the window size and overlap (in number of frames)\n",
    "window_size = 60  # e.g. 60 frames per window\n",
    "overlap = 30      # e.g. 30 frames overlap between windows\n",
    "\n",
    "# Calculate the time-windowed metrics using the updated method with extra options:\n",
    "# - use_bounds: whether to enforce parameter bounds in the MSD fit (True)\n",
    "# - max_D: maximum allowed diffusion coefficient (here, 5)\n",
    "# - allow_partial_window: whether to process windows smaller than window_size (False)\n",
    "# - min_window_size: minimum required frames per window (set to window_size)\n",
    "particle_metrics.calculate_time_windowed_metrics(window_size=window_size,\n",
    "                                                   overlap=overlap,\n",
    "                                                   use_bounds=True, # (applying an upper bound for D)\n",
    "                                                   max_D=5,\n",
    "                                                   allow_partial_window=False, # (skip windows that have fewer frames than the specified window size)\n",
    "                                                   min_window_size=window_size)\n",
    "\n",
    "# Retrieve the DataFrames\n",
    "time_averaged_df = particle_metrics.get_time_averaged_df()\n",
    "time_windowed_df = particle_metrics.get_time_windowed_df()\n",
    "msd_lagtime_df = particle_metrics.msd_lagtime_df\n",
    "\n",
    "# Optionally, inspect the outputs\n",
    "print(\"Time-Averaged DataFrame:\")\n",
    "display(time_averaged_df.head())\n",
    "print(\"Time-Windowed DataFrame:\")\n",
    "display(time_windowed_df.head())\n",
    "print(\"MSD Lag Time DataFrame:\")\n",
    "display(msd_lagtime_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ParticleMetrics\n",
    "particle_metrics = spt.ParticleMetrics(pathfix_df, time_between_frames)\n",
    "\n",
    "# Calculate all features, without calculating time-windowed metrics initially\n",
    "metrics_df = particle_metrics.calculate_all_features(calculate_time_windowed=False)\n",
    "\n",
    "# Specify the window size and overlap\n",
    "window_size = 60#60#60  # for example, 20 frames\n",
    "overlap = 30#30#30  # for example, 10 frames\n",
    "\n",
    "# Calculate the time-windowed metrics with the specified window size and overlap\n",
    "particle_metrics.calculate_time_windowed_metrics(window_size=window_size, overlap=overlap)\n",
    "\n",
    "# Retrieve the DataFrames\n",
    "time_averaged_df = particle_metrics.get_time_averaged_df()\n",
    "time_windowed_df = particle_metrics.get_time_windowed_df()\n",
    "msd_lagtime_df = particle_metrics.msd_lagtime_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save those dfs\n",
    "time_averaged_df.to_csv(saved_data + 'time_averaged_df.csv', index=False)\n",
    "time_windowed_df.to_csv(saved_data + 'time_windowed_df.csv', index=False)\n",
    "msd_lagtime_df.to_csv(saved_data + 'msd_lagtime_df.csv', index=False)\n",
    "metrics_df.to_csv(saved_data + 'metrics_df.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_averaged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windowed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_motion = spt.add_motion_class(metrics_df, time_windowed_df, time_window = 60)#60))\n",
    "metrics_df_motion.to_csv(saved_data + 'metrics_df_motion.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# immediately cut out the unlabelled rows, because they ALWAYS occur at the end of tracks, where windows aren't big enough to get a D or an Alpha\n",
    "\n",
    "print(f'Before: {len(metrics_df_motion)}')\n",
    "metrics_df_motion_filt = metrics_df_motion[metrics_df_motion.motion_class != 'unlabeled']\n",
    "print(f'After: {len(metrics_df_motion_filt)}')\n",
    "\n",
    "print('These rows are always at the end of tracks, where windows are too small to get a D or an Alpha')\n",
    "# save that also\n",
    "metrics_df_motion_filt.to_csv(saved_data + 'metrics_df_motion_filt.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dfs\n",
    "time_averaged_df = pd.read_csv(saved_data + 'time_averaged_df.csv')\n",
    "time_windowed_df = pd.read_csv(saved_data + 'time_windowed_df.csv')\n",
    "msd_lagtime_df = pd.read_csv(saved_data + 'msd_lagtime_df.csv')\n",
    "metrics_df = pd.read_csv(saved_data + 'metrics_df.csv')\n",
    "metrics_df_motion = pd.read_csv(saved_data + 'metrics_df_motion.csv')\n",
    "metrics_df_motion_filt = pd.read_csv(saved_data + 'metrics_df_motion_filt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the rest mate\n",
    "\n",
    "metrics_df_motion_filt.unique_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the GC\n",
    "location = 'GC'\n",
    "metrics_df_location = metrics_df[metrics_df['Location'] == location]\n",
    "time_windowed_df_location = time_windowed_df[time_windowed_df['Location'] == location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_motion.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through cells, make sure they look OK.\n",
    "metrics_df_motion_filt_condition = metrics_df_motion_filt[metrics_df_motion_filt['condition'] == 'Condition_20H20S_cort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in metrics_df_motion_filt_condition.filename.unique():\n",
    "    print(cell)\n",
    "    metrics_df_cell = metrics_df_motion_filt_condition[metrics_df_motion_filt_condition['filename'] == cell]\n",
    "    # time_windowed_df_cell = time_windowed_df[time_windowed_df['cell'] == cell]\n",
    "    spt.napari_visualize_image_with_tracksdev2(metrics_df_cell, condition=None,\n",
    "                                                    cell=None, location=None, save_movie_flag=False)#master_dir=config.MASTER + 'data', condition=None, cell=None feature='Track_ID'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt.napari_visualize_image_with_tracksdev2(metrics_df_motion_filt, condition=None,\n",
    "                                                    cell=None, location=None, save_movie_flag=False)#master_dir=config.MASTER + 'data', condition=None, cell=None feature='Track_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay so first, check the freehalo ones. Are they complete nonsense?\n",
    "\n",
    "metrics_df_motion_filt.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt.napari_visualize_image_with_tracksdev2(metrics_df, condition='Condition_freehalo_cort',\n",
    "                                                    cell=None, location=None, save_movie_flag=False)#master_dir=config.MASTER + 'data', condition=None, cell=None feature='Track_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_motion.motion_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df of only the unlabeled ones\n",
    "unlabelled_df = metrics_df_motion[metrics_df_motion_filt.motion_class == 'unlabeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by unique_id and get the motion classes for each unique_id\n",
    "grouped = metrics_df_motion.groupby('unique_id')['motion_class'].unique()\n",
    "\n",
    "# Filter unique_ids that have both 'unlabeled' and any other class\n",
    "unique_ids_with_unlabeled_and_others = grouped[grouped.apply(lambda x: 'unlabeled' in x and len(x) > 1)].index\n",
    "\n",
    "# Convert to a list if needed\n",
    "unique_ids_with_unlabeled_and_others = unique_ids_with_unlabeled_and_others.tolist()\n",
    "\n",
    "print(unique_ids_with_unlabeled_and_others)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare a given unique ID that HAS unlabelled in it, with one that doesn't\n",
    "# unique ids with unlabelled\n",
    "# make a df of only the unlabeled\n",
    "\n",
    "# unique_id_unlabelled = metrics_df_motion[metrics_df_motion.motion_class == 'unlabeled'].unique_id.unique()\n",
    "\n",
    "\n",
    "# pick a random one with numpy random\n",
    "unique_id_unlabelled_random = np.random.choice(unique_ids_with_unlabeled_and_others)\n",
    "# get a single particle df for that unique id from the metrics df_motion and the metrics_df_motion_filt\n",
    "single_particle_df_unlabelled = metrics_df_motion[metrics_df_motion.unique_id == unique_id_unlabelled_random]\n",
    "single_particle_df_unlabelled_filt = metrics_df_motion_filt[metrics_df_motion_filt.unique_id == unique_id_unlabelled_random]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_particle_df_unlabelled.frame.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in single_particle_df_unlabelled.frame.unique():\n",
    "    print(f'For frame {frame}, the motion class is {single_particle_df_unlabelled[single_particle_df_unlabelled.frame == frame].motion_class.unique()}')\n",
    "    # the length of the track is\n",
    "print(f'The length of the track is {len(single_particle_df_unlabelled)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so what unique id is this?\n",
    "unique_id_unlabelled_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the time windowed df, how many windows are there\n",
    "# get a single particle df from the time windowed df\n",
    "single_particle_df_unlabelled_time_windowed = time_windowed_df[time_windowed_df.unique_id == unique_id_unlabelled_random]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_particle_df_unlabelled_time_windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_particle_df_unlabelled_filt.frame.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt.napari_visualize_image_with_tracksdev2(metrics_df, condition='Condition_20H20S_cort', cell=None, location='GC', save_movie_flag=False, feature='particle', steps=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt.napari_visualize_image_with_tracksdev2(metrics_df_motion_filt, condition='Condition_20H20S_cort', cell=None, location='NN', save_movie_flag=True, feature='particle', steps=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt.napari_visualize_image_with_tracksdev2(metrics_df, condition='Condition_freehalo_cort', cell='loc-NN_type-cort_freehalo_005_cropped_tracked', location='NN', save_movie_flag=True, feature='particle', steps=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful coloured plots of tracks in a single cell\n",
    "\n",
    "tracks_df = spt.plot_tracks_static(\n",
    "    metrics_df_motion_filt,\n",
    "    filename=None,\n",
    "    file_id=None,\n",
    "    location=None,\n",
    "    condition=None,\n",
    "    time_start=None, # in seconds\n",
    "    time_end=None,\n",
    "    # color_by='motion_class',\n",
    "    color_by='motion_class',\n",
    "    motion_type=None,\n",
    "    overlay_image=False,\n",
    "\n",
    "    scale_bar_length=2,\n",
    "    scale_bar_position=(0.9, 0.1),\n",
    "    scale_bar_color='white',\n",
    "    transparent_background=True,\n",
    "    save_path=spt.config.MASTER + 'static_trackplots/',\n",
    "    display_final_frame=True,\n",
    "    max_projection=False,\n",
    "    contrast_limits=None,  # Tuple: (lower, upper) or None for auto\n",
    "    invert_image=False,\n",
    "\n",
    "    gradient = False,  # Frame interval in seconds\n",
    "    colorway = 'Dark2',\n",
    "    order = ['subdiffusive', 'normal', 'superdiffusive'],\n",
    "    # figsize_multiplier = 1,\n",
    "    dpi=200 ) # Multiplier for DPI to increase resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windowed_df.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df of only certain conditions\n",
    "includedconditions = ['Condition_20H20S_cort', 'Condition_77H20S_cort', 'Condition_20H77S_cort']\n",
    "time_windowed_df_included = time_windowed_df[time_windowed_df['condition'].isin(includedconditions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windowed_df_included_location = time_windowed_df_included[time_windowed_df_included['Location'] == 'GC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the median avg_speed_um_s per filename for each condition and put it in a new dataframe\n",
    "time_windowed_df_included_median = time_windowed_df_included_location.groupby(['filename', 'condition'])['avg_speed_um_s'].median().reset_index()\n",
    "time_windowed_df_included_median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windowed_df_included_location.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the median avg_speed_um_s per filename for each condition and put it in a new dataframe\n",
    "time_windowed_df_included_median = time_windowed_df_included_location.groupby(['filename', 'condition'])['diffusion_coefficient'].median().reset_index()\n",
    "time_windowed_df_included_median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'diffusion_coefficient'#'avg_speed_um_s' #'anomalous_exponent'\n",
    "x_category = 'condition'\n",
    "# order = orderofconditions\n",
    "# order = ['CB','NN','GC']\n",
    "order = includedconditions\n",
    "\n",
    "spt.plot_boxplots(time_windowed_df_included_median, feature, x_category, font_size=22, order=order, palette='colorblind', \n",
    "                background='white', transparent=True, line_color='white', show_plot=True, \n",
    "                master_dir=None, grid=True, bw=False, strip=True, y_max=None, figsize=(8, 12), \n",
    "                annotate_median=True, rotation=90, dotsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'avg_speed_um_s'#'avg_speed_um_s' #'anomalous_exponent'\n",
    "x_category = 'condition'\n",
    "# order = orderofconditions\n",
    "# order = ['CB','NN','GC']\n",
    "order = includedconditions\n",
    "\n",
    "spt.plot_boxplots(time_windowed_df_included_median, feature, x_category, font_size=22, order=order, palette='colorblind', \n",
    "                background='white', transparent=True, line_color='white', show_plot=True, \n",
    "                master_dir=None, grid=True, bw=False, strip=True, y_max=None, figsize=(8, 12), \n",
    "                annotate_median=True, rotation=90, dotsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gallery of tracks by motion class\n",
    "\n",
    "spt.plot_tracks_by_motion_class(\n",
    "    time_windowed_df, \n",
    "    metrics_df, \n",
    "    num_tracks=40, \n",
    "    colormap='Dark2', \n",
    "    axis_range=None, \n",
    "    show_annotations=False, \n",
    "    order=['subdiffusive', 'normal', 'superdiffusive'], \n",
    "    transparent_background=True, \n",
    "    annotation_color=\"white\",\n",
    "    text_size=16, \n",
    "    figsizemultiplier=5,  # Overall figure size multiplier for adaptable subplot size\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windowed_df.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditionsorder = ['Condition_10seconds','Condition_5seconds',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windowed_df.filename[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a new function that adds a new column called 'cellID' to each row, based on the bit of the filename that is after 'cell-' and before '_cropped'\n",
    "# this will be used to identify the cell in the napari viewer\n",
    "def add_cellID(df):\n",
    "    df['cellID'] = df.filename.str.extract(r'cell-(\\d+)_cropped')\n",
    "    return df\n",
    "# also make a function that does this for the bit after 'power-' and before '_cell'\n",
    "def add_powerID(df):\n",
    "    df['powerID'] = df.filename.str.extract(r'power-(\\d+)_cell')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_laserpower(df):\n",
    "    df['laserpower'] = df.condition.str.extract(r'power-(\\d+)_cell')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.cellID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2df = add_powerID(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2df.powerID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_metadata(df, filename_col):\n",
    "    \"\"\"\n",
    "    Extracts 'power' and 'cellID' from the filename column and adds them as new columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a column with filenames.\n",
    "        filename_col (str): Name of the column containing filenames.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with 'power' and 'cellID' columns.\n",
    "    \"\"\"\n",
    "    def parse_filename(filename):\n",
    "        match = re.search(r'power-(\\d+percent)_cell-(\\d+)', filename)\n",
    "        if match:\n",
    "            power = match.group(1)  # Extracts power (e.g., '25percent')\n",
    "            cellID = int(match.group(2))  # Extracts cell number as integer\n",
    "            return power, cellID\n",
    "        return None, None  # If no match, return None values\n",
    "\n",
    "    df[['power', 'cellID']] = df[filename_col].apply(lambda x: pd.Series(parse_filename(x)))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = extract_metadata(df, 'filename')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_metadata(time_windowed_df, 'filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosencondition = 'Condition_10seconds'\n",
    "#filter the df\n",
    "df_filtered = df[df['condition'] == chosencondition]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditionsorder = ['25percent', '50percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df = df_filtered[df_filtered['cellID'] == 7]\n",
    "feature = 'avg_speed_um_s'#'avg_speed_um_s' #'anomalous_exponent'\n",
    "x_category = 'power'\n",
    "# order = orderofconditions\n",
    "# order = ['CB','NN','GC']\n",
    "order = conditionsorder\n",
    "\n",
    "spt.plot_boxplots(cell_df, feature, x_category, font_size=18, order=order, palette='colorblind', \n",
    "                background='white', transparent=True, line_color='white', show_plot=True, \n",
    "                master_dir=None, grid=True, bw=False, strip=True, y_max=None, figsize=(10, 12), \n",
    "                annotate_median=True, rotation=90, dotsize = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditionsorder = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'avg_speed_um_s'#'avg_speed_um_s' #'anomalous_exponent'\n",
    "x_category = 'condition'\n",
    "# order = orderofconditions\n",
    "# order = ['CB','NN','GC']\n",
    "order = orderofconditions\n",
    "\n",
    "spt.plot_boxplots(time_windowed_df, feature, x_category, font_size=18, order=order, palette='colorblind', \n",
    "                background='white', transparent=True, line_color='white', show_plot=True, \n",
    "                master_dir=None, grid=True, bw=False, strip=False, y_max=None, figsize=(10, 12), \n",
    "                annotate_median=True, rotation=90, dotsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time to plot first segment length\n",
    "\n",
    "# feature = 'segment_len_um'\n",
    "\n",
    "# # NEW SHIT\n",
    "\n",
    "# spt.plot_histograms(time_windowed_df, feature, bins=100, separate=None, xlimit=None, small_multiples=False, palette='colorblind',\n",
    "#                     use_kde=False, show_plot=True, master_dir=None, tick_interval=5, average='mean', order=None, \n",
    "#                     grid=False, background='white', transparent=False, line_color='black', font_size=9, showavg=True,\n",
    "#                     export_format='png', return_svg=False, x_range=None, y_range=None, percentage=True, \n",
    "#                     log_scale=False, log_base=10, alpha=1, log_axis_label='log', save_folder=None, figsize=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'diffusion_coefficient'\n",
    "save_folder = 'A:/mshannon/2025/March/FIGURE5/histo/'\n",
    "\n",
    "spt.plot_histograms(time_windowed_df, feature, bins=100, separate='condition_short', xlimit=None, small_multiples=True, palette='colorblind',\n",
    "                    use_kde=True, kde_fill = True, show_plot=True, master_dir=None, tick_interval=2, average='median', \n",
    "                    order=dynein_conds,# here, you use the ORDER thing to define what is plotted in the histo :)\n",
    "                    grid=False,  condition_colors=condition_colors, background='white', transparent=True, line_color='black', font_size=7, showavg=False,\n",
    "                    export_format='svg', return_svg=False, \n",
    "                    x_range=[-4,2],\n",
    "                      y_range=[0,0.7], \n",
    "                      percentage=True,log_scale=True, log_base=10, alpha=0.4, log_axis_label='actual', save_folder=save_folder, figsize=(5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt.plot_classification_pie_charts(time_windowed_df, group_by='condition', colormap_name='Dark2', order = ['subdiffusive', 'normal', 'superdiffusive'], figsize=(30, 20), font_size=24, label_font_size=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unlabeled!\n",
    "time_windowed_df = time_windowed_df[time_windowed_df.motion_class != 'unlabeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows per condition\n",
    "time_windowed_df.groupby('condition').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_category = 'condition'\n",
    "# order = orderofconditions\n",
    "# order = ['CB','NN','GC']\n",
    "\n",
    "spt.plot_stacked_bar(time_windowed_df, x_category, order=order, font_size=12, colormap='Dark2', figsize=(10, 10), \n",
    "                     background='white', transparent=True, line_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = 'avg_speed_um_s'\n",
    "y_var = 'n_frames'\n",
    "\n",
    "spt.plot_combo_hist_scatter_kde(time_averaged_df, x_var, y_var, font_size=12, palette='mako', scatter_color=\".15\", hist_bins=50, kde_levels=5, \n",
    "                                figsize=(6, 6), separate=None, order=None, x_min=None, x_max=None, y_min=None, y_max=None, horizontal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenID = np.random.choice(cleaned_df['unique_id'].unique())\n",
    "\n",
    "pathfix_single = spt.extract_single_particle_df(pathfix_df, unique_id = chosenID)\n",
    "cleaned_single = spt.extract_single_particle_df(cleaned_df, unique_id = chosenID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfix_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_single = spt.extract_single_particle_df(cleaned_df, unique_id = chosenID)\n",
    "cleaned_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alright, the unique ids have no .0 on the end for the pathfix_single\n",
    "# This is good! Just check it works with the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfix_single = spt.extract_single_particle_df(pathfix_df)\n",
    "pathfix_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtstubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "# list of possible thresholds\n",
    "# segment_length_thresholds = [0.95, 1.0, 1.05]\n",
    "\n",
    "\n",
    "\n",
    "segment_length_threshold = 1.0 # segment length threshold in um. \n",
    "print(segment_length_threshold)\n",
    "min_track_length_seconds = 0.2  # Specify the minimum track duration in seconds\n",
    "# time_between_frames = config.TIME_BETWEEN_FRAMES  # From config\n",
    "\n",
    "# Run the cleaning function\n",
    "pathfix_df, pathfix_removed_unique_ids, pathfix_report = spt.pathfixer(\n",
    "    df_filtstubs, \n",
    "    segment_length_threshold=segment_length_threshold, \n",
    "    min_track_length_seconds=min_track_length_seconds,\n",
    "    time_between_frames=time_between_frames\n",
    ")\n",
    "\n",
    "# saved the cleaned df\n",
    "# pathfix_df.to_csv(saved_data + 'cleaned_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt.visualize_track_changes_with_filtering(\n",
    "    df_filtstubs, pathfix_df, pathfix_removed_unique_ids,\n",
    "    filename=None,  \n",
    "    time_start=25, time_end=27, \n",
    "    time_between_frames=0.1, \n",
    "    plot_size_px=150, \n",
    "    dpi=100,\n",
    "    pixel_size_um=0.1,\n",
    "    figsize=(18, 6),  \n",
    "    line_width=1.2,  \n",
    "    alpha_range=(0.3, 1.0),  \n",
    "    transparent_background=True,\n",
    "    overlay_image=True,  \n",
    "    master_dir=master,  \n",
    "    condition=None,  \n",
    "    max_projection=True,  \n",
    "    display_final_frame=False,  \n",
    "    contrast_limits=None,  \n",
    "    invert_image=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOD! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoSPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
